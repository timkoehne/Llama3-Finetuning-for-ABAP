{"cells":[{"cell_type":"markdown","source":["###Mount Google Drive"],"metadata":{"id":"4Oj7AKUGrgQX"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"VHE1YG64rc0K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723657984353,"user_tz":-120,"elapsed":18385,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}},"outputId":"34c69833-a6ed-4932-cc51-2b124e05034c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["###Install dependencies"],"metadata":{"id":"kK0Vt0rQr-kn"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1723658032914,"user_tz":-120,"elapsed":48567,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[],"source":["%%capture\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302,"referenced_widgets":["db49e49621574df8a520f89ebd3e9246","98b7f22d0a0546a4ac0ddc5058e22a99","0d65287653f04084b876fad7ee37de2d","f943deaacfff400d9c0d0a6a7921d038","95a586b379e843cca62f3a3ef6a68df8","ee56c03ac4ff4775976fd5d93aee4db3","9d48ec1368c34bf18e48ace81ed09414","4d663962b8a7449ab104c2b861a467ad","f757ed71584f449288f145e30d08be42","8167879135bd4fdb9513e523e7f06f37","d820fbe9247c4bd8b3c533fc479e165f","ef384b1a06334cf699e9f160d5942b50","9878fd6fadf6455698399e0e4c146eed","c418c9d59ceb48e4944b189747494a90","f3845f66a52f448dab3f18852c9bb3c7","8c88907729dd46d6bfab905fc487f760","3e3b21960b1d40eea9d4d550baacdae1","992307ef82e34dad800c2be62cd60bd7","0594694eb2474ad581b8be7c1b01c12c","f27725a5fff64522adc9bd86e75454fa","47eada1597fe4bb898d102ed168d355b","b9d6c9cec73a4e6d94ebaab5c0ef6824","52b141f2c1f64f9789879ebd0b06e0e9","135f37244033443eb4b10b68e269dc33","d0e32721f8cd4852ba61fa8dec933a31","05369cc8af714b638ed996fea3cca420","83bec57c9b054ddb8a4f182cc54b8583","941551fd611a4ea996c73732eb2dfc63","9e78525aea974b8fad268cdfec4a8e6e","ebb91e90c83d4f5baf89c671f4517a75","78d8e452884b4b098fe131badbbfe9b1","75fd406c2ce841089f7e57605b8e6e8f","9d0188395a7645b483253091d4dabf73","b308f492c43d4e2e99189ba631331ef5","9f382c4589b84312b79ead87857711fb","9c67994d18ed45f48c042b77b858ddc8","84c37d823e12413e8cc8891b1f83917c","22e8e260223248b79b93986a66a050ae","24e8118175ce48fe971f5948a83aa398","b56bab12033745e980866d1bd17878e7","03dd14ebd205437cb6e1e647425aa93c","cf36697d04884db4b5ae3e4a0f8b8a68","5de4bf9140cf4b7ca538d8062f73d884","eebcc86a49ca4512af63f385fa75f04f","d2cdbf98d1384d5dadf70a110a8e4839","c02eef0320ee4d488717cffc287871b0","8dc0788c5cf64cb894973e8d1708a3a4","c9dd53d0427442baa943920681eebe1d","19da87e24e434711a9933d33db06cf75","e9d88c6eee64452d9c3d161f1e2aceba","714da808fb4840198634b599a89c1d28","af54793e5b9243dba802da7302c40b14","da76e3ccbc29436489a02219201ff24f","89fa660be9e0492b9002defdb6757676","a9f1584681a6408bac3e2c76aaed8322"]},"executionInfo":{"elapsed":101373,"status":"ok","timestamp":1723658134281,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"QmUBVEnvCDJv","outputId":"3e1bff05-5ded-48f0-c754-4fea6e647c4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db49e49621574df8a520f89ebd3e9246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef384b1a06334cf699e9f160d5942b50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b141f2c1f64f9789879ebd0b06e0e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b308f492c43d4e2e99189ba631331ef5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2cdbf98d1384d5dadf70a110a8e4839"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 8192 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["### Add LoRA Adapters"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5606,"status":"ok","timestamp":1723658139885,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"6bZsfBuZDeCL","outputId":"1cb584d2-1a54-4771-841a-7e28ae8e2eac"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["033b491ec3fb40bcb4cf91da5dd6219d","b9c2a8d13f6a4f35b6571ae875e64b18","b9ca0f86db2a4f77a8d4ae799e6a975e","236fadb1927e40caa5f9162afdf12e48","8d770542415a448f999dd864aee21492","11ffc9b7d20e4c198c3f414d9fe22d82","df802bc79ef34c82a5b697519bacb5b3","6d7a2cdbbe01479aa85fc1c9b4d1e76c","52579aab9b5c458594f8bac3783f3abf","38c4f3e358a64ef8a0c5a5620835a114","350424ff7a3149f395bb621542d39477","0c09ef097d4041baa61b43c4fc981ead","e7c4e2123ae943b9b9bde4290bb77bd3","b16f843c0c6c429090019bc1c9da967b","fbffc27a3e16476ea4b6ba985c1abff8","154a2b8b1bfb474889db22dae419572b","4182623d1f634428885898ce12ce4b9f","abec852a001d4642ae881cbb0413a646","f626cd366948482c94851c3b7b9dade7","f0f0d05514bd4e80a81de096000f019e","bcdc61982fcc41dea86949d799c64342","08e2660c2263434a8bc2c65cde6cd8bf"]},"executionInfo":{"elapsed":4140,"status":"ok","timestamp":1723658144017,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"LjY75GoYUCB8","outputId":"36c0b119-d864-4352-e509-9267d730e31a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033b491ec3fb40bcb4cf91da5dd6219d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c09ef097d4041baa61b43c4fc981ead"}},"metadata":{}}],"source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","```abap\n","{}\n","```\n","\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"response\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"json\", data_files='/content/drive/MyDrive/DS2.json', split=\"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Training the model"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["5a3517bdbbba4fe38e6fa9a115d6bfe8","0892d88595164e9590fa448787d86391","42de22b8125543968b38147d87950500","936584ca18314bbba5caacea49413477","2d2dde5adbc3452aa840c9b4e9d7d896","81d5d844d37f479ab5c10b1cd8a088b1","d5b533c8e33c4963a422a9812ab139c4","928b74e3c5784c3697ae80a954c24524","5c7885180cd84afbbaf0cea5eeb856ab","350ed1178e5e4577ae6e6d1f4ed9e100","3e3f97748a72473ba36e1c3f061b46ce"]},"executionInfo":{"elapsed":6665,"status":"ok","timestamp":1723658150678,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"95_Nn-89DhsL","outputId":"b5a59f00-507b-49fe-e939-5a979f69414a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a3517bdbbba4fe38e6fa9a115d6bfe8"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        num_train_epochs = 5, # Set this for 1 full training run.\n","        max_steps = -1,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1723658150679,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"2ejIt2xSNKKp","outputId":"5e97ba3f-bc97-4f02-8a23-2720ad1712ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","5.984 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"76d3a746-e586-4076-c6f8-f1620c6853cd","executionInfo":{"status":"ok","timestamp":1723663710979,"user_tz":-120,"elapsed":5560307,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 1,000 | Num Epochs = 5\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 625\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [625/625 1:32:14, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.394100</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.390500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.522200</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.375400</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.043700</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.332100</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.977900</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.888500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.847300</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.681300</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.712000</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.718800</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.569200</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.875200</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.583300</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.806400</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.616700</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.646700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.597100</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.634500</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.598200</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.674500</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.553500</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.583000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.701800</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.613400</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.617900</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.540500</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.612000</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.678800</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.542200</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.532100</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.547100</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.604100</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.707100</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.581800</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.601400</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.455700</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.668800</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.620800</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.591800</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.553400</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.433900</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.473600</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.857000</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.466100</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.644300</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.484700</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.599600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.504500</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.613500</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.642300</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.501600</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.692500</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.595600</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.546200</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.487100</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.518400</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.611000</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.547400</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.672500</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.542800</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.457500</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.414900</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.593100</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.606700</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.542500</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.622200</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.578300</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.686000</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.539400</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.463600</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.578000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.509900</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.566000</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.639500</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.540900</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.626700</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.680900</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.575200</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.610900</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.461000</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.616000</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.616000</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.563300</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.524500</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.558600</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.534700</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.657300</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.514900</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.520400</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.512700</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.488800</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.540500</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.570100</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.517700</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.471400</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.400400</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.498700</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.663300</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>0.464600</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>0.668600</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>0.557000</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>0.604400</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.550500</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>0.574400</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>0.554700</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>0.603500</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>0.606100</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.619300</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>0.545000</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.554000</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>0.646700</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>0.630700</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.493500</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>0.575800</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>0.568300</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>0.567900</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>0.536800</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.543600</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>0.577400</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>0.475900</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>0.663200</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>0.589900</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.516600</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.521000</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>0.484800</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>0.466300</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>0.463500</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.398900</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>0.653600</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>0.390600</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>0.433400</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>0.518400</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.526200</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>0.373000</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>0.453600</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>0.578200</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>0.512500</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.387000</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>0.414600</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>0.414100</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>0.469900</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>0.426900</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.476200</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>0.474000</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>0.508100</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>0.509900</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>0.426700</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.444700</td>\n","    </tr>\n","    <tr>\n","      <td>151</td>\n","      <td>0.371100</td>\n","    </tr>\n","    <tr>\n","      <td>152</td>\n","      <td>0.538700</td>\n","    </tr>\n","    <tr>\n","      <td>153</td>\n","      <td>0.390700</td>\n","    </tr>\n","    <tr>\n","      <td>154</td>\n","      <td>0.545400</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>0.436200</td>\n","    </tr>\n","    <tr>\n","      <td>156</td>\n","      <td>0.485300</td>\n","    </tr>\n","    <tr>\n","      <td>157</td>\n","      <td>0.509700</td>\n","    </tr>\n","    <tr>\n","      <td>158</td>\n","      <td>0.492100</td>\n","    </tr>\n","    <tr>\n","      <td>159</td>\n","      <td>0.463300</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.470300</td>\n","    </tr>\n","    <tr>\n","      <td>161</td>\n","      <td>0.480900</td>\n","    </tr>\n","    <tr>\n","      <td>162</td>\n","      <td>0.452900</td>\n","    </tr>\n","    <tr>\n","      <td>163</td>\n","      <td>0.463600</td>\n","    </tr>\n","    <tr>\n","      <td>164</td>\n","      <td>0.524900</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>0.394500</td>\n","    </tr>\n","    <tr>\n","      <td>166</td>\n","      <td>0.587900</td>\n","    </tr>\n","    <tr>\n","      <td>167</td>\n","      <td>0.444800</td>\n","    </tr>\n","    <tr>\n","      <td>168</td>\n","      <td>0.599900</td>\n","    </tr>\n","    <tr>\n","      <td>169</td>\n","      <td>0.530000</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.581100</td>\n","    </tr>\n","    <tr>\n","      <td>171</td>\n","      <td>0.430500</td>\n","    </tr>\n","    <tr>\n","      <td>172</td>\n","      <td>0.389100</td>\n","    </tr>\n","    <tr>\n","      <td>173</td>\n","      <td>0.375400</td>\n","    </tr>\n","    <tr>\n","      <td>174</td>\n","      <td>0.437000</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.435500</td>\n","    </tr>\n","    <tr>\n","      <td>176</td>\n","      <td>0.458600</td>\n","    </tr>\n","    <tr>\n","      <td>177</td>\n","      <td>0.453500</td>\n","    </tr>\n","    <tr>\n","      <td>178</td>\n","      <td>0.496700</td>\n","    </tr>\n","    <tr>\n","      <td>179</td>\n","      <td>0.609700</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.506400</td>\n","    </tr>\n","    <tr>\n","      <td>181</td>\n","      <td>0.560800</td>\n","    </tr>\n","    <tr>\n","      <td>182</td>\n","      <td>0.439400</td>\n","    </tr>\n","    <tr>\n","      <td>183</td>\n","      <td>0.506700</td>\n","    </tr>\n","    <tr>\n","      <td>184</td>\n","      <td>0.505300</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>0.431300</td>\n","    </tr>\n","    <tr>\n","      <td>186</td>\n","      <td>0.497700</td>\n","    </tr>\n","    <tr>\n","      <td>187</td>\n","      <td>0.517000</td>\n","    </tr>\n","    <tr>\n","      <td>188</td>\n","      <td>0.445600</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>0.526500</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.526400</td>\n","    </tr>\n","    <tr>\n","      <td>191</td>\n","      <td>0.355300</td>\n","    </tr>\n","    <tr>\n","      <td>192</td>\n","      <td>0.537500</td>\n","    </tr>\n","    <tr>\n","      <td>193</td>\n","      <td>0.503000</td>\n","    </tr>\n","    <tr>\n","      <td>194</td>\n","      <td>0.498100</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>0.393300</td>\n","    </tr>\n","    <tr>\n","      <td>196</td>\n","      <td>0.548400</td>\n","    </tr>\n","    <tr>\n","      <td>197</td>\n","      <td>0.476200</td>\n","    </tr>\n","    <tr>\n","      <td>198</td>\n","      <td>0.543000</td>\n","    </tr>\n","    <tr>\n","      <td>199</td>\n","      <td>0.465500</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.500100</td>\n","    </tr>\n","    <tr>\n","      <td>201</td>\n","      <td>0.401100</td>\n","    </tr>\n","    <tr>\n","      <td>202</td>\n","      <td>0.371900</td>\n","    </tr>\n","    <tr>\n","      <td>203</td>\n","      <td>0.473700</td>\n","    </tr>\n","    <tr>\n","      <td>204</td>\n","      <td>0.408100</td>\n","    </tr>\n","    <tr>\n","      <td>205</td>\n","      <td>0.462700</td>\n","    </tr>\n","    <tr>\n","      <td>206</td>\n","      <td>0.420100</td>\n","    </tr>\n","    <tr>\n","      <td>207</td>\n","      <td>0.513500</td>\n","    </tr>\n","    <tr>\n","      <td>208</td>\n","      <td>0.525000</td>\n","    </tr>\n","    <tr>\n","      <td>209</td>\n","      <td>0.425100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.474900</td>\n","    </tr>\n","    <tr>\n","      <td>211</td>\n","      <td>0.595200</td>\n","    </tr>\n","    <tr>\n","      <td>212</td>\n","      <td>0.549300</td>\n","    </tr>\n","    <tr>\n","      <td>213</td>\n","      <td>0.539900</td>\n","    </tr>\n","    <tr>\n","      <td>214</td>\n","      <td>0.497900</td>\n","    </tr>\n","    <tr>\n","      <td>215</td>\n","      <td>0.392100</td>\n","    </tr>\n","    <tr>\n","      <td>216</td>\n","      <td>0.503900</td>\n","    </tr>\n","    <tr>\n","      <td>217</td>\n","      <td>0.498600</td>\n","    </tr>\n","    <tr>\n","      <td>218</td>\n","      <td>0.407500</td>\n","    </tr>\n","    <tr>\n","      <td>219</td>\n","      <td>0.441800</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.458500</td>\n","    </tr>\n","    <tr>\n","      <td>221</td>\n","      <td>0.611100</td>\n","    </tr>\n","    <tr>\n","      <td>222</td>\n","      <td>0.492700</td>\n","    </tr>\n","    <tr>\n","      <td>223</td>\n","      <td>0.483900</td>\n","    </tr>\n","    <tr>\n","      <td>224</td>\n","      <td>0.460300</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>0.479900</td>\n","    </tr>\n","    <tr>\n","      <td>226</td>\n","      <td>0.425400</td>\n","    </tr>\n","    <tr>\n","      <td>227</td>\n","      <td>0.559300</td>\n","    </tr>\n","    <tr>\n","      <td>228</td>\n","      <td>0.487500</td>\n","    </tr>\n","    <tr>\n","      <td>229</td>\n","      <td>0.622500</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.485300</td>\n","    </tr>\n","    <tr>\n","      <td>231</td>\n","      <td>0.422500</td>\n","    </tr>\n","    <tr>\n","      <td>232</td>\n","      <td>0.499000</td>\n","    </tr>\n","    <tr>\n","      <td>233</td>\n","      <td>0.417400</td>\n","    </tr>\n","    <tr>\n","      <td>234</td>\n","      <td>0.497200</td>\n","    </tr>\n","    <tr>\n","      <td>235</td>\n","      <td>0.414400</td>\n","    </tr>\n","    <tr>\n","      <td>236</td>\n","      <td>0.442600</td>\n","    </tr>\n","    <tr>\n","      <td>237</td>\n","      <td>0.526400</td>\n","    </tr>\n","    <tr>\n","      <td>238</td>\n","      <td>0.588000</td>\n","    </tr>\n","    <tr>\n","      <td>239</td>\n","      <td>0.554000</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.379500</td>\n","    </tr>\n","    <tr>\n","      <td>241</td>\n","      <td>0.450200</td>\n","    </tr>\n","    <tr>\n","      <td>242</td>\n","      <td>0.560500</td>\n","    </tr>\n","    <tr>\n","      <td>243</td>\n","      <td>0.468600</td>\n","    </tr>\n","    <tr>\n","      <td>244</td>\n","      <td>0.446000</td>\n","    </tr>\n","    <tr>\n","      <td>245</td>\n","      <td>0.446600</td>\n","    </tr>\n","    <tr>\n","      <td>246</td>\n","      <td>0.411400</td>\n","    </tr>\n","    <tr>\n","      <td>247</td>\n","      <td>0.510900</td>\n","    </tr>\n","    <tr>\n","      <td>248</td>\n","      <td>0.418500</td>\n","    </tr>\n","    <tr>\n","      <td>249</td>\n","      <td>0.478200</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.490100</td>\n","    </tr>\n","    <tr>\n","      <td>251</td>\n","      <td>0.367100</td>\n","    </tr>\n","    <tr>\n","      <td>252</td>\n","      <td>0.439300</td>\n","    </tr>\n","    <tr>\n","      <td>253</td>\n","      <td>0.413400</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>0.361000</td>\n","    </tr>\n","    <tr>\n","      <td>255</td>\n","      <td>0.326900</td>\n","    </tr>\n","    <tr>\n","      <td>256</td>\n","      <td>0.367000</td>\n","    </tr>\n","    <tr>\n","      <td>257</td>\n","      <td>0.378900</td>\n","    </tr>\n","    <tr>\n","      <td>258</td>\n","      <td>0.320800</td>\n","    </tr>\n","    <tr>\n","      <td>259</td>\n","      <td>0.374800</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.378800</td>\n","    </tr>\n","    <tr>\n","      <td>261</td>\n","      <td>0.352800</td>\n","    </tr>\n","    <tr>\n","      <td>262</td>\n","      <td>0.366400</td>\n","    </tr>\n","    <tr>\n","      <td>263</td>\n","      <td>0.332400</td>\n","    </tr>\n","    <tr>\n","      <td>264</td>\n","      <td>0.354600</td>\n","    </tr>\n","    <tr>\n","      <td>265</td>\n","      <td>0.417900</td>\n","    </tr>\n","    <tr>\n","      <td>266</td>\n","      <td>0.388500</td>\n","    </tr>\n","    <tr>\n","      <td>267</td>\n","      <td>0.363900</td>\n","    </tr>\n","    <tr>\n","      <td>268</td>\n","      <td>0.361900</td>\n","    </tr>\n","    <tr>\n","      <td>269</td>\n","      <td>0.392000</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.273100</td>\n","    </tr>\n","    <tr>\n","      <td>271</td>\n","      <td>0.354000</td>\n","    </tr>\n","    <tr>\n","      <td>272</td>\n","      <td>0.495100</td>\n","    </tr>\n","    <tr>\n","      <td>273</td>\n","      <td>0.332600</td>\n","    </tr>\n","    <tr>\n","      <td>274</td>\n","      <td>0.408800</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>0.360200</td>\n","    </tr>\n","    <tr>\n","      <td>276</td>\n","      <td>0.430900</td>\n","    </tr>\n","    <tr>\n","      <td>277</td>\n","      <td>0.405900</td>\n","    </tr>\n","    <tr>\n","      <td>278</td>\n","      <td>0.446900</td>\n","    </tr>\n","    <tr>\n","      <td>279</td>\n","      <td>0.448900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.369700</td>\n","    </tr>\n","    <tr>\n","      <td>281</td>\n","      <td>0.446300</td>\n","    </tr>\n","    <tr>\n","      <td>282</td>\n","      <td>0.437700</td>\n","    </tr>\n","    <tr>\n","      <td>283</td>\n","      <td>0.372300</td>\n","    </tr>\n","    <tr>\n","      <td>284</td>\n","      <td>0.428600</td>\n","    </tr>\n","    <tr>\n","      <td>285</td>\n","      <td>0.412900</td>\n","    </tr>\n","    <tr>\n","      <td>286</td>\n","      <td>0.347300</td>\n","    </tr>\n","    <tr>\n","      <td>287</td>\n","      <td>0.350900</td>\n","    </tr>\n","    <tr>\n","      <td>288</td>\n","      <td>0.427400</td>\n","    </tr>\n","    <tr>\n","      <td>289</td>\n","      <td>0.368700</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.472800</td>\n","    </tr>\n","    <tr>\n","      <td>291</td>\n","      <td>0.293700</td>\n","    </tr>\n","    <tr>\n","      <td>292</td>\n","      <td>0.333800</td>\n","    </tr>\n","    <tr>\n","      <td>293</td>\n","      <td>0.417700</td>\n","    </tr>\n","    <tr>\n","      <td>294</td>\n","      <td>0.337200</td>\n","    </tr>\n","    <tr>\n","      <td>295</td>\n","      <td>0.395000</td>\n","    </tr>\n","    <tr>\n","      <td>296</td>\n","      <td>0.331600</td>\n","    </tr>\n","    <tr>\n","      <td>297</td>\n","      <td>0.419300</td>\n","    </tr>\n","    <tr>\n","      <td>298</td>\n","      <td>0.350400</td>\n","    </tr>\n","    <tr>\n","      <td>299</td>\n","      <td>0.337100</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.373000</td>\n","    </tr>\n","    <tr>\n","      <td>301</td>\n","      <td>0.365500</td>\n","    </tr>\n","    <tr>\n","      <td>302</td>\n","      <td>0.421300</td>\n","    </tr>\n","    <tr>\n","      <td>303</td>\n","      <td>0.416800</td>\n","    </tr>\n","    <tr>\n","      <td>304</td>\n","      <td>0.450900</td>\n","    </tr>\n","    <tr>\n","      <td>305</td>\n","      <td>0.333000</td>\n","    </tr>\n","    <tr>\n","      <td>306</td>\n","      <td>0.391300</td>\n","    </tr>\n","    <tr>\n","      <td>307</td>\n","      <td>0.338500</td>\n","    </tr>\n","    <tr>\n","      <td>308</td>\n","      <td>0.329400</td>\n","    </tr>\n","    <tr>\n","      <td>309</td>\n","      <td>0.312600</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.367700</td>\n","    </tr>\n","    <tr>\n","      <td>311</td>\n","      <td>0.352800</td>\n","    </tr>\n","    <tr>\n","      <td>312</td>\n","      <td>0.383600</td>\n","    </tr>\n","    <tr>\n","      <td>313</td>\n","      <td>0.389900</td>\n","    </tr>\n","    <tr>\n","      <td>314</td>\n","      <td>0.424500</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>0.366200</td>\n","    </tr>\n","    <tr>\n","      <td>316</td>\n","      <td>0.396200</td>\n","    </tr>\n","    <tr>\n","      <td>317</td>\n","      <td>0.369800</td>\n","    </tr>\n","    <tr>\n","      <td>318</td>\n","      <td>0.333600</td>\n","    </tr>\n","    <tr>\n","      <td>319</td>\n","      <td>0.384100</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>0.281800</td>\n","    </tr>\n","    <tr>\n","      <td>321</td>\n","      <td>0.436800</td>\n","    </tr>\n","    <tr>\n","      <td>322</td>\n","      <td>0.344500</td>\n","    </tr>\n","    <tr>\n","      <td>323</td>\n","      <td>0.396900</td>\n","    </tr>\n","    <tr>\n","      <td>324</td>\n","      <td>0.378000</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>0.340300</td>\n","    </tr>\n","    <tr>\n","      <td>326</td>\n","      <td>0.324000</td>\n","    </tr>\n","    <tr>\n","      <td>327</td>\n","      <td>0.386000</td>\n","    </tr>\n","    <tr>\n","      <td>328</td>\n","      <td>0.434200</td>\n","    </tr>\n","    <tr>\n","      <td>329</td>\n","      <td>0.384500</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>0.414800</td>\n","    </tr>\n","    <tr>\n","      <td>331</td>\n","      <td>0.319100</td>\n","    </tr>\n","    <tr>\n","      <td>332</td>\n","      <td>0.430600</td>\n","    </tr>\n","    <tr>\n","      <td>333</td>\n","      <td>0.397800</td>\n","    </tr>\n","    <tr>\n","      <td>334</td>\n","      <td>0.381300</td>\n","    </tr>\n","    <tr>\n","      <td>335</td>\n","      <td>0.340600</td>\n","    </tr>\n","    <tr>\n","      <td>336</td>\n","      <td>0.360200</td>\n","    </tr>\n","    <tr>\n","      <td>337</td>\n","      <td>0.504400</td>\n","    </tr>\n","    <tr>\n","      <td>338</td>\n","      <td>0.338400</td>\n","    </tr>\n","    <tr>\n","      <td>339</td>\n","      <td>0.348000</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>0.388300</td>\n","    </tr>\n","    <tr>\n","      <td>341</td>\n","      <td>0.374100</td>\n","    </tr>\n","    <tr>\n","      <td>342</td>\n","      <td>0.426300</td>\n","    </tr>\n","    <tr>\n","      <td>343</td>\n","      <td>0.397300</td>\n","    </tr>\n","    <tr>\n","      <td>344</td>\n","      <td>0.380000</td>\n","    </tr>\n","    <tr>\n","      <td>345</td>\n","      <td>0.371600</td>\n","    </tr>\n","    <tr>\n","      <td>346</td>\n","      <td>0.393700</td>\n","    </tr>\n","    <tr>\n","      <td>347</td>\n","      <td>0.339000</td>\n","    </tr>\n","    <tr>\n","      <td>348</td>\n","      <td>0.338800</td>\n","    </tr>\n","    <tr>\n","      <td>349</td>\n","      <td>0.345800</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.373700</td>\n","    </tr>\n","    <tr>\n","      <td>351</td>\n","      <td>0.322300</td>\n","    </tr>\n","    <tr>\n","      <td>352</td>\n","      <td>0.478100</td>\n","    </tr>\n","    <tr>\n","      <td>353</td>\n","      <td>0.337900</td>\n","    </tr>\n","    <tr>\n","      <td>354</td>\n","      <td>0.303100</td>\n","    </tr>\n","    <tr>\n","      <td>355</td>\n","      <td>0.373300</td>\n","    </tr>\n","    <tr>\n","      <td>356</td>\n","      <td>0.419800</td>\n","    </tr>\n","    <tr>\n","      <td>357</td>\n","      <td>0.363500</td>\n","    </tr>\n","    <tr>\n","      <td>358</td>\n","      <td>0.339200</td>\n","    </tr>\n","    <tr>\n","      <td>359</td>\n","      <td>0.329400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>0.338600</td>\n","    </tr>\n","    <tr>\n","      <td>361</td>\n","      <td>0.384500</td>\n","    </tr>\n","    <tr>\n","      <td>362</td>\n","      <td>0.361800</td>\n","    </tr>\n","    <tr>\n","      <td>363</td>\n","      <td>0.350000</td>\n","    </tr>\n","    <tr>\n","      <td>364</td>\n","      <td>0.387400</td>\n","    </tr>\n","    <tr>\n","      <td>365</td>\n","      <td>0.403500</td>\n","    </tr>\n","    <tr>\n","      <td>366</td>\n","      <td>0.539200</td>\n","    </tr>\n","    <tr>\n","      <td>367</td>\n","      <td>0.398700</td>\n","    </tr>\n","    <tr>\n","      <td>368</td>\n","      <td>0.340000</td>\n","    </tr>\n","    <tr>\n","      <td>369</td>\n","      <td>0.386900</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>0.351600</td>\n","    </tr>\n","    <tr>\n","      <td>371</td>\n","      <td>0.441800</td>\n","    </tr>\n","    <tr>\n","      <td>372</td>\n","      <td>0.281500</td>\n","    </tr>\n","    <tr>\n","      <td>373</td>\n","      <td>0.455500</td>\n","    </tr>\n","    <tr>\n","      <td>374</td>\n","      <td>0.419500</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>0.310000</td>\n","    </tr>\n","    <tr>\n","      <td>376</td>\n","      <td>0.366900</td>\n","    </tr>\n","    <tr>\n","      <td>377</td>\n","      <td>0.333100</td>\n","    </tr>\n","    <tr>\n","      <td>378</td>\n","      <td>0.225600</td>\n","    </tr>\n","    <tr>\n","      <td>379</td>\n","      <td>0.325900</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>0.248700</td>\n","    </tr>\n","    <tr>\n","      <td>381</td>\n","      <td>0.288100</td>\n","    </tr>\n","    <tr>\n","      <td>382</td>\n","      <td>0.330400</td>\n","    </tr>\n","    <tr>\n","      <td>383</td>\n","      <td>0.298300</td>\n","    </tr>\n","    <tr>\n","      <td>384</td>\n","      <td>0.256000</td>\n","    </tr>\n","    <tr>\n","      <td>385</td>\n","      <td>0.281200</td>\n","    </tr>\n","    <tr>\n","      <td>386</td>\n","      <td>0.286600</td>\n","    </tr>\n","    <tr>\n","      <td>387</td>\n","      <td>0.261500</td>\n","    </tr>\n","    <tr>\n","      <td>388</td>\n","      <td>0.256300</td>\n","    </tr>\n","    <tr>\n","      <td>389</td>\n","      <td>0.272000</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>0.351700</td>\n","    </tr>\n","    <tr>\n","      <td>391</td>\n","      <td>0.265800</td>\n","    </tr>\n","    <tr>\n","      <td>392</td>\n","      <td>0.231600</td>\n","    </tr>\n","    <tr>\n","      <td>393</td>\n","      <td>0.278600</td>\n","    </tr>\n","    <tr>\n","      <td>394</td>\n","      <td>0.341300</td>\n","    </tr>\n","    <tr>\n","      <td>395</td>\n","      <td>0.261400</td>\n","    </tr>\n","    <tr>\n","      <td>396</td>\n","      <td>0.282300</td>\n","    </tr>\n","    <tr>\n","      <td>397</td>\n","      <td>0.242100</td>\n","    </tr>\n","    <tr>\n","      <td>398</td>\n","      <td>0.250600</td>\n","    </tr>\n","    <tr>\n","      <td>399</td>\n","      <td>0.256500</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.235600</td>\n","    </tr>\n","    <tr>\n","      <td>401</td>\n","      <td>0.266200</td>\n","    </tr>\n","    <tr>\n","      <td>402</td>\n","      <td>0.233900</td>\n","    </tr>\n","    <tr>\n","      <td>403</td>\n","      <td>0.342900</td>\n","    </tr>\n","    <tr>\n","      <td>404</td>\n","      <td>0.304300</td>\n","    </tr>\n","    <tr>\n","      <td>405</td>\n","      <td>0.282400</td>\n","    </tr>\n","    <tr>\n","      <td>406</td>\n","      <td>0.330100</td>\n","    </tr>\n","    <tr>\n","      <td>407</td>\n","      <td>0.285900</td>\n","    </tr>\n","    <tr>\n","      <td>408</td>\n","      <td>0.244800</td>\n","    </tr>\n","    <tr>\n","      <td>409</td>\n","      <td>0.314300</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>0.262400</td>\n","    </tr>\n","    <tr>\n","      <td>411</td>\n","      <td>0.319400</td>\n","    </tr>\n","    <tr>\n","      <td>412</td>\n","      <td>0.291800</td>\n","    </tr>\n","    <tr>\n","      <td>413</td>\n","      <td>0.276100</td>\n","    </tr>\n","    <tr>\n","      <td>414</td>\n","      <td>0.236700</td>\n","    </tr>\n","    <tr>\n","      <td>415</td>\n","      <td>0.278000</td>\n","    </tr>\n","    <tr>\n","      <td>416</td>\n","      <td>0.336000</td>\n","    </tr>\n","    <tr>\n","      <td>417</td>\n","      <td>0.311200</td>\n","    </tr>\n","    <tr>\n","      <td>418</td>\n","      <td>0.259700</td>\n","    </tr>\n","    <tr>\n","      <td>419</td>\n","      <td>0.285700</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>0.272200</td>\n","    </tr>\n","    <tr>\n","      <td>421</td>\n","      <td>0.237300</td>\n","    </tr>\n","    <tr>\n","      <td>422</td>\n","      <td>0.279000</td>\n","    </tr>\n","    <tr>\n","      <td>423</td>\n","      <td>0.282000</td>\n","    </tr>\n","    <tr>\n","      <td>424</td>\n","      <td>0.245200</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>0.235300</td>\n","    </tr>\n","    <tr>\n","      <td>426</td>\n","      <td>0.249500</td>\n","    </tr>\n","    <tr>\n","      <td>427</td>\n","      <td>0.295100</td>\n","    </tr>\n","    <tr>\n","      <td>428</td>\n","      <td>0.250500</td>\n","    </tr>\n","    <tr>\n","      <td>429</td>\n","      <td>0.368600</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>0.304000</td>\n","    </tr>\n","    <tr>\n","      <td>431</td>\n","      <td>0.302200</td>\n","    </tr>\n","    <tr>\n","      <td>432</td>\n","      <td>0.307000</td>\n","    </tr>\n","    <tr>\n","      <td>433</td>\n","      <td>0.283800</td>\n","    </tr>\n","    <tr>\n","      <td>434</td>\n","      <td>0.288300</td>\n","    </tr>\n","    <tr>\n","      <td>435</td>\n","      <td>0.254800</td>\n","    </tr>\n","    <tr>\n","      <td>436</td>\n","      <td>0.251800</td>\n","    </tr>\n","    <tr>\n","      <td>437</td>\n","      <td>0.314700</td>\n","    </tr>\n","    <tr>\n","      <td>438</td>\n","      <td>0.319900</td>\n","    </tr>\n","    <tr>\n","      <td>439</td>\n","      <td>0.266300</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>0.271200</td>\n","    </tr>\n","    <tr>\n","      <td>441</td>\n","      <td>0.289700</td>\n","    </tr>\n","    <tr>\n","      <td>442</td>\n","      <td>0.312200</td>\n","    </tr>\n","    <tr>\n","      <td>443</td>\n","      <td>0.216400</td>\n","    </tr>\n","    <tr>\n","      <td>444</td>\n","      <td>0.276800</td>\n","    </tr>\n","    <tr>\n","      <td>445</td>\n","      <td>0.251900</td>\n","    </tr>\n","    <tr>\n","      <td>446</td>\n","      <td>0.269800</td>\n","    </tr>\n","    <tr>\n","      <td>447</td>\n","      <td>0.273600</td>\n","    </tr>\n","    <tr>\n","      <td>448</td>\n","      <td>0.250700</td>\n","    </tr>\n","    <tr>\n","      <td>449</td>\n","      <td>0.266000</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.241700</td>\n","    </tr>\n","    <tr>\n","      <td>451</td>\n","      <td>0.295100</td>\n","    </tr>\n","    <tr>\n","      <td>452</td>\n","      <td>0.303100</td>\n","    </tr>\n","    <tr>\n","      <td>453</td>\n","      <td>0.244800</td>\n","    </tr>\n","    <tr>\n","      <td>454</td>\n","      <td>0.273100</td>\n","    </tr>\n","    <tr>\n","      <td>455</td>\n","      <td>0.283100</td>\n","    </tr>\n","    <tr>\n","      <td>456</td>\n","      <td>0.254900</td>\n","    </tr>\n","    <tr>\n","      <td>457</td>\n","      <td>0.316800</td>\n","    </tr>\n","    <tr>\n","      <td>458</td>\n","      <td>0.262600</td>\n","    </tr>\n","    <tr>\n","      <td>459</td>\n","      <td>0.225000</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>0.231800</td>\n","    </tr>\n","    <tr>\n","      <td>461</td>\n","      <td>0.292700</td>\n","    </tr>\n","    <tr>\n","      <td>462</td>\n","      <td>0.281000</td>\n","    </tr>\n","    <tr>\n","      <td>463</td>\n","      <td>0.356200</td>\n","    </tr>\n","    <tr>\n","      <td>464</td>\n","      <td>0.353400</td>\n","    </tr>\n","    <tr>\n","      <td>465</td>\n","      <td>0.307300</td>\n","    </tr>\n","    <tr>\n","      <td>466</td>\n","      <td>0.240900</td>\n","    </tr>\n","    <tr>\n","      <td>467</td>\n","      <td>0.278200</td>\n","    </tr>\n","    <tr>\n","      <td>468</td>\n","      <td>0.289700</td>\n","    </tr>\n","    <tr>\n","      <td>469</td>\n","      <td>0.274500</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>0.278400</td>\n","    </tr>\n","    <tr>\n","      <td>471</td>\n","      <td>0.384400</td>\n","    </tr>\n","    <tr>\n","      <td>472</td>\n","      <td>0.302300</td>\n","    </tr>\n","    <tr>\n","      <td>473</td>\n","      <td>0.308500</td>\n","    </tr>\n","    <tr>\n","      <td>474</td>\n","      <td>0.251200</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>0.266800</td>\n","    </tr>\n","    <tr>\n","      <td>476</td>\n","      <td>0.275800</td>\n","    </tr>\n","    <tr>\n","      <td>477</td>\n","      <td>0.269200</td>\n","    </tr>\n","    <tr>\n","      <td>478</td>\n","      <td>0.255700</td>\n","    </tr>\n","    <tr>\n","      <td>479</td>\n","      <td>0.357200</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>0.263900</td>\n","    </tr>\n","    <tr>\n","      <td>481</td>\n","      <td>0.337800</td>\n","    </tr>\n","    <tr>\n","      <td>482</td>\n","      <td>0.226900</td>\n","    </tr>\n","    <tr>\n","      <td>483</td>\n","      <td>0.256800</td>\n","    </tr>\n","    <tr>\n","      <td>484</td>\n","      <td>0.296600</td>\n","    </tr>\n","    <tr>\n","      <td>485</td>\n","      <td>0.282400</td>\n","    </tr>\n","    <tr>\n","      <td>486</td>\n","      <td>0.268700</td>\n","    </tr>\n","    <tr>\n","      <td>487</td>\n","      <td>0.275900</td>\n","    </tr>\n","    <tr>\n","      <td>488</td>\n","      <td>0.313200</td>\n","    </tr>\n","    <tr>\n","      <td>489</td>\n","      <td>0.288000</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>0.274000</td>\n","    </tr>\n","    <tr>\n","      <td>491</td>\n","      <td>0.300700</td>\n","    </tr>\n","    <tr>\n","      <td>492</td>\n","      <td>0.279900</td>\n","    </tr>\n","    <tr>\n","      <td>493</td>\n","      <td>0.298900</td>\n","    </tr>\n","    <tr>\n","      <td>494</td>\n","      <td>0.349800</td>\n","    </tr>\n","    <tr>\n","      <td>495</td>\n","      <td>0.198000</td>\n","    </tr>\n","    <tr>\n","      <td>496</td>\n","      <td>0.289400</td>\n","    </tr>\n","    <tr>\n","      <td>497</td>\n","      <td>0.318800</td>\n","    </tr>\n","    <tr>\n","      <td>498</td>\n","      <td>0.213300</td>\n","    </tr>\n","    <tr>\n","      <td>499</td>\n","      <td>0.290100</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.257100</td>\n","    </tr>\n","    <tr>\n","      <td>501</td>\n","      <td>0.192900</td>\n","    </tr>\n","    <tr>\n","      <td>502</td>\n","      <td>0.208000</td>\n","    </tr>\n","    <tr>\n","      <td>503</td>\n","      <td>0.238500</td>\n","    </tr>\n","    <tr>\n","      <td>504</td>\n","      <td>0.193100</td>\n","    </tr>\n","    <tr>\n","      <td>505</td>\n","      <td>0.191900</td>\n","    </tr>\n","    <tr>\n","      <td>506</td>\n","      <td>0.166300</td>\n","    </tr>\n","    <tr>\n","      <td>507</td>\n","      <td>0.176300</td>\n","    </tr>\n","    <tr>\n","      <td>508</td>\n","      <td>0.185700</td>\n","    </tr>\n","    <tr>\n","      <td>509</td>\n","      <td>0.186400</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>0.175600</td>\n","    </tr>\n","    <tr>\n","      <td>511</td>\n","      <td>0.234200</td>\n","    </tr>\n","    <tr>\n","      <td>512</td>\n","      <td>0.198600</td>\n","    </tr>\n","    <tr>\n","      <td>513</td>\n","      <td>0.187500</td>\n","    </tr>\n","    <tr>\n","      <td>514</td>\n","      <td>0.163000</td>\n","    </tr>\n","    <tr>\n","      <td>515</td>\n","      <td>0.211700</td>\n","    </tr>\n","    <tr>\n","      <td>516</td>\n","      <td>0.230200</td>\n","    </tr>\n","    <tr>\n","      <td>517</td>\n","      <td>0.199600</td>\n","    </tr>\n","    <tr>\n","      <td>518</td>\n","      <td>0.149300</td>\n","    </tr>\n","    <tr>\n","      <td>519</td>\n","      <td>0.219100</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>0.206200</td>\n","    </tr>\n","    <tr>\n","      <td>521</td>\n","      <td>0.216700</td>\n","    </tr>\n","    <tr>\n","      <td>522</td>\n","      <td>0.238500</td>\n","    </tr>\n","    <tr>\n","      <td>523</td>\n","      <td>0.202200</td>\n","    </tr>\n","    <tr>\n","      <td>524</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>525</td>\n","      <td>0.193300</td>\n","    </tr>\n","    <tr>\n","      <td>526</td>\n","      <td>0.234300</td>\n","    </tr>\n","    <tr>\n","      <td>527</td>\n","      <td>0.233100</td>\n","    </tr>\n","    <tr>\n","      <td>528</td>\n","      <td>0.185000</td>\n","    </tr>\n","    <tr>\n","      <td>529</td>\n","      <td>0.180200</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>0.210900</td>\n","    </tr>\n","    <tr>\n","      <td>531</td>\n","      <td>0.221700</td>\n","    </tr>\n","    <tr>\n","      <td>532</td>\n","      <td>0.191900</td>\n","    </tr>\n","    <tr>\n","      <td>533</td>\n","      <td>0.170500</td>\n","    </tr>\n","    <tr>\n","      <td>534</td>\n","      <td>0.253900</td>\n","    </tr>\n","    <tr>\n","      <td>535</td>\n","      <td>0.207000</td>\n","    </tr>\n","    <tr>\n","      <td>536</td>\n","      <td>0.253200</td>\n","    </tr>\n","    <tr>\n","      <td>537</td>\n","      <td>0.236300</td>\n","    </tr>\n","    <tr>\n","      <td>538</td>\n","      <td>0.192100</td>\n","    </tr>\n","    <tr>\n","      <td>539</td>\n","      <td>0.238600</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>0.224500</td>\n","    </tr>\n","    <tr>\n","      <td>541</td>\n","      <td>0.216800</td>\n","    </tr>\n","    <tr>\n","      <td>542</td>\n","      <td>0.193700</td>\n","    </tr>\n","    <tr>\n","      <td>543</td>\n","      <td>0.181600</td>\n","    </tr>\n","    <tr>\n","      <td>544</td>\n","      <td>0.157500</td>\n","    </tr>\n","    <tr>\n","      <td>545</td>\n","      <td>0.177700</td>\n","    </tr>\n","    <tr>\n","      <td>546</td>\n","      <td>0.207400</td>\n","    </tr>\n","    <tr>\n","      <td>547</td>\n","      <td>0.183800</td>\n","    </tr>\n","    <tr>\n","      <td>548</td>\n","      <td>0.212700</td>\n","    </tr>\n","    <tr>\n","      <td>549</td>\n","      <td>0.207900</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.192200</td>\n","    </tr>\n","    <tr>\n","      <td>551</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>552</td>\n","      <td>0.170300</td>\n","    </tr>\n","    <tr>\n","      <td>553</td>\n","      <td>0.222700</td>\n","    </tr>\n","    <tr>\n","      <td>554</td>\n","      <td>0.184100</td>\n","    </tr>\n","    <tr>\n","      <td>555</td>\n","      <td>0.171600</td>\n","    </tr>\n","    <tr>\n","      <td>556</td>\n","      <td>0.163700</td>\n","    </tr>\n","    <tr>\n","      <td>557</td>\n","      <td>0.223700</td>\n","    </tr>\n","    <tr>\n","      <td>558</td>\n","      <td>0.189100</td>\n","    </tr>\n","    <tr>\n","      <td>559</td>\n","      <td>0.246300</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>0.198800</td>\n","    </tr>\n","    <tr>\n","      <td>561</td>\n","      <td>0.160200</td>\n","    </tr>\n","    <tr>\n","      <td>562</td>\n","      <td>0.172400</td>\n","    </tr>\n","    <tr>\n","      <td>563</td>\n","      <td>0.249600</td>\n","    </tr>\n","    <tr>\n","      <td>564</td>\n","      <td>0.241700</td>\n","    </tr>\n","    <tr>\n","      <td>565</td>\n","      <td>0.170900</td>\n","    </tr>\n","    <tr>\n","      <td>566</td>\n","      <td>0.217000</td>\n","    </tr>\n","    <tr>\n","      <td>567</td>\n","      <td>0.259500</td>\n","    </tr>\n","    <tr>\n","      <td>568</td>\n","      <td>0.165100</td>\n","    </tr>\n","    <tr>\n","      <td>569</td>\n","      <td>0.154300</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>0.217100</td>\n","    </tr>\n","    <tr>\n","      <td>571</td>\n","      <td>0.181400</td>\n","    </tr>\n","    <tr>\n","      <td>572</td>\n","      <td>0.217400</td>\n","    </tr>\n","    <tr>\n","      <td>573</td>\n","      <td>0.199800</td>\n","    </tr>\n","    <tr>\n","      <td>574</td>\n","      <td>0.188200</td>\n","    </tr>\n","    <tr>\n","      <td>575</td>\n","      <td>0.187400</td>\n","    </tr>\n","    <tr>\n","      <td>576</td>\n","      <td>0.266300</td>\n","    </tr>\n","    <tr>\n","      <td>577</td>\n","      <td>0.217800</td>\n","    </tr>\n","    <tr>\n","      <td>578</td>\n","      <td>0.260000</td>\n","    </tr>\n","    <tr>\n","      <td>579</td>\n","      <td>0.177400</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>0.195600</td>\n","    </tr>\n","    <tr>\n","      <td>581</td>\n","      <td>0.285400</td>\n","    </tr>\n","    <tr>\n","      <td>582</td>\n","      <td>0.224700</td>\n","    </tr>\n","    <tr>\n","      <td>583</td>\n","      <td>0.177900</td>\n","    </tr>\n","    <tr>\n","      <td>584</td>\n","      <td>0.176700</td>\n","    </tr>\n","    <tr>\n","      <td>585</td>\n","      <td>0.149900</td>\n","    </tr>\n","    <tr>\n","      <td>586</td>\n","      <td>0.213500</td>\n","    </tr>\n","    <tr>\n","      <td>587</td>\n","      <td>0.189100</td>\n","    </tr>\n","    <tr>\n","      <td>588</td>\n","      <td>0.195900</td>\n","    </tr>\n","    <tr>\n","      <td>589</td>\n","      <td>0.182300</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>0.176600</td>\n","    </tr>\n","    <tr>\n","      <td>591</td>\n","      <td>0.193800</td>\n","    </tr>\n","    <tr>\n","      <td>592</td>\n","      <td>0.183200</td>\n","    </tr>\n","    <tr>\n","      <td>593</td>\n","      <td>0.217500</td>\n","    </tr>\n","    <tr>\n","      <td>594</td>\n","      <td>0.152000</td>\n","    </tr>\n","    <tr>\n","      <td>595</td>\n","      <td>0.177800</td>\n","    </tr>\n","    <tr>\n","      <td>596</td>\n","      <td>0.181000</td>\n","    </tr>\n","    <tr>\n","      <td>597</td>\n","      <td>0.220500</td>\n","    </tr>\n","    <tr>\n","      <td>598</td>\n","      <td>0.198300</td>\n","    </tr>\n","    <tr>\n","      <td>599</td>\n","      <td>0.191800</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.189100</td>\n","    </tr>\n","    <tr>\n","      <td>601</td>\n","      <td>0.199800</td>\n","    </tr>\n","    <tr>\n","      <td>602</td>\n","      <td>0.207700</td>\n","    </tr>\n","    <tr>\n","      <td>603</td>\n","      <td>0.187300</td>\n","    </tr>\n","    <tr>\n","      <td>604</td>\n","      <td>0.202200</td>\n","    </tr>\n","    <tr>\n","      <td>605</td>\n","      <td>0.142600</td>\n","    </tr>\n","    <tr>\n","      <td>606</td>\n","      <td>0.184400</td>\n","    </tr>\n","    <tr>\n","      <td>607</td>\n","      <td>0.227900</td>\n","    </tr>\n","    <tr>\n","      <td>608</td>\n","      <td>0.173100</td>\n","    </tr>\n","    <tr>\n","      <td>609</td>\n","      <td>0.186500</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>0.220000</td>\n","    </tr>\n","    <tr>\n","      <td>611</td>\n","      <td>0.185900</td>\n","    </tr>\n","    <tr>\n","      <td>612</td>\n","      <td>0.323700</td>\n","    </tr>\n","    <tr>\n","      <td>613</td>\n","      <td>0.184100</td>\n","    </tr>\n","    <tr>\n","      <td>614</td>\n","      <td>0.198000</td>\n","    </tr>\n","    <tr>\n","      <td>615</td>\n","      <td>0.182900</td>\n","    </tr>\n","    <tr>\n","      <td>616</td>\n","      <td>0.157400</td>\n","    </tr>\n","    <tr>\n","      <td>617</td>\n","      <td>0.177700</td>\n","    </tr>\n","    <tr>\n","      <td>618</td>\n","      <td>0.204400</td>\n","    </tr>\n","    <tr>\n","      <td>619</td>\n","      <td>0.218900</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>0.173100</td>\n","    </tr>\n","    <tr>\n","      <td>621</td>\n","      <td>0.205900</td>\n","    </tr>\n","    <tr>\n","      <td>622</td>\n","      <td>0.214600</td>\n","    </tr>\n","    <tr>\n","      <td>623</td>\n","      <td>0.203400</td>\n","    </tr>\n","    <tr>\n","      <td>624</td>\n","      <td>0.183400</td>\n","    </tr>\n","    <tr>\n","      <td>625</td>\n","      <td>0.197200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCqnaKmlO1U9","outputId":"c457cfef-a4df-4f4a-9253-269698f66d73","executionInfo":{"status":"ok","timestamp":1723663710980,"user_tz":-120,"elapsed":7,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["5556.7524 seconds used for training.\n","92.61 minutes used for training.\n","Peak reserved memory = 10.004 GB.\n","Peak reserved memory for training = 4.02 GB.\n","Peak reserved memory % of max memory = 67.833 %.\n","Peak reserved memory for training % of max memory = 27.258 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["### Save LoRA Adapter"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"a26092a6-cfad-42e6-ee42-dd11e2dfe8a0","executionInfo":{"status":"ok","timestamp":1723663712870,"user_tz":-120,"elapsed":1895,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":10}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n","# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"]},{"cell_type":"markdown","metadata":{"id":"TCv4vXHd61i7"},"source":["### GGUF / llama.cpp Conversion\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FqfebeAdT073","executionInfo":{"status":"ok","timestamp":1723665426094,"user_tz":-120,"elapsed":1713227,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22a5fe31-bd62-45df-a093-77e9e2ca5c62"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 5.7G\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 5.48 out of 12.67 RAM for saving.\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:02<00:02,  7.07it/s]We will save to Disk and not RAM now.\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [02:22<00:00,  4.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n","Unsloth: Saving model/pytorch_model-00001-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00002-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00003-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00004-of-00004.bin...\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Converting llama model. Can use fast conversion = False.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n"," \"-____-\"     In total, you will have to wait at least 16 minutes.\n","\n","Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n","Unsloth: [1] Converting model at model into f16 GGUF format.\n","The output location will be ./model/unsloth.F16.gguf\n","This will take 3 minutes...\n","INFO:hf-to-gguf:Loading model: model\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00004.bin'\n","INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00004.bin'\n","INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00004.bin'\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00004-of-00004.bin'\n","INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:gguf: context length = 131072\n","INFO:hf-to-gguf:gguf: embedding length = 4096\n","INFO:hf-to-gguf:gguf: feed forward length = 14336\n","INFO:hf-to-gguf:gguf: head count = 32\n","INFO:hf-to-gguf:gguf: key-value head count = 8\n","INFO:hf-to-gguf:gguf: rope theta = 500000.0\n","INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n","INFO:hf-to-gguf:gguf: file type = 1\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:gguf.vocab:Adding 280147 merge(s).\n","INFO:gguf.vocab:Setting special token type bos to 128000\n","INFO:gguf.vocab:Setting special token type eos to 128001\n","INFO:gguf.vocab:Setting special token type pad to 128004\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:model/unsloth.F16.gguf: n_tensors = 292, total_size = 16.1G\n","Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.1G/16.1G [03:46<00:00, 71.1Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to model/unsloth.F16.gguf\n","Unsloth: Conversion completed! Output location: ./model/unsloth.F16.gguf\n","Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n","main: build = 3584 (5fd89a70)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing './model/unsloth.F16.gguf' to './model/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n","llama_model_loader: loaded meta data with 27 key-value pairs and 292 tensors from ./model/unsloth.F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8b Bnb 4bit\n","llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n","llama_model_loader: - kv   4:                           general.finetune str              = bnb-4bit\n","llama_model_loader: - kv   5:                           general.basename str              = meta-llama-3.1\n","llama_model_loader: - kv   6:                         general.size_label str              = 8B\n","llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n","llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n","llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n","llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  15:                          general.file_type u32              = 1\n","llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n","llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n","llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n","llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n","llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ä  Ä \", \"Ä  Ä Ä Ä \", \"Ä Ä  Ä Ä \", \"...\n","llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n","llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128001\n","llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n","llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   66 tensors\n","llama_model_loader: - type  f16:  226 tensors\n","[   1/ 292]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n","[   2/ 292]                    token_embd.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n","[   3/ 292]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[   4/ 292]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[   5/ 292]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[   6/ 292]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[   7/ 292]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[   8/ 292]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[   9/ 292]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  10/ 292]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  11/ 292]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  12/ 292]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  13/ 292]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  14/ 292]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  15/ 292]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  16/ 292]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  17/ 292]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  18/ 292]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  19/ 292]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  20/ 292]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  21/ 292]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  22/ 292]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  23/ 292]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  24/ 292]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  25/ 292]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  26/ 292]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  27/ 292]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  28/ 292]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  29/ 292]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  30/ 292]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  31/ 292]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  32/ 292]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  33/ 292]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  34/ 292]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  35/ 292]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  36/ 292]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  37/ 292]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  38/ 292]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  39/ 292]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  40/ 292]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  41/ 292]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  42/ 292]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  43/ 292]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  44/ 292]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  45/ 292]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  46/ 292]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  47/ 292]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  48/ 292]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  49/ 292]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  50/ 292]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  51/ 292]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  52/ 292]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  53/ 292]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  54/ 292]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  55/ 292]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  56/ 292]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  57/ 292]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  58/ 292]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  59/ 292]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  60/ 292]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  61/ 292]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  62/ 292]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  63/ 292]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  64/ 292]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  65/ 292]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  66/ 292]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  67/ 292]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  68/ 292]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  69/ 292]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  70/ 292]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  71/ 292]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  72/ 292]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  73/ 292]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  74/ 292]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  75/ 292]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  76/ 292]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  77/ 292]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  78/ 292]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  79/ 292]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  80/ 292]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  81/ 292]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  82/ 292]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  83/ 292]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  84/ 292]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  85/ 292]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  86/ 292]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  87/ 292]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  88/ 292]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  89/ 292]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  90/ 292]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  91/ 292]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  92/ 292]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  93/ 292]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  94/ 292]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  95/ 292]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  96/ 292]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  97/ 292]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  98/ 292]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  99/ 292]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 100/ 292]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 101/ 292]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 102/ 292]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 103/ 292]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 104/ 292]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 105/ 292]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 106/ 292]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 107/ 292]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 108/ 292]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 109/ 292]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 110/ 292]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 111/ 292]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 112/ 292]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 113/ 292]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 114/ 292]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 115/ 292]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 116/ 292]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 117/ 292]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 118/ 292]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 119/ 292]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 120/ 292]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 121/ 292]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 122/ 292]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 123/ 292]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 124/ 292]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 125/ 292]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 126/ 292]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 127/ 292]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 128/ 292]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 129/ 292]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 130/ 292]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 131/ 292]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 132/ 292]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 133/ 292]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 134/ 292]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 135/ 292]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 136/ 292]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 137/ 292]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 138/ 292]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 139/ 292]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 140/ 292]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 141/ 292]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 142/ 292]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 143/ 292]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 144/ 292]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 145/ 292]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 146/ 292]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 147/ 292]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 148/ 292]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 149/ 292]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 150/ 292]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 151/ 292]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 152/ 292]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 153/ 292]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 154/ 292]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 155/ 292]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 156/ 292]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 157/ 292]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 158/ 292]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 159/ 292]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 160/ 292]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 161/ 292]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 162/ 292]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 163/ 292]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 164/ 292]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 165/ 292]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 166/ 292]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 167/ 292]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 168/ 292]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 169/ 292]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 170/ 292]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 171/ 292]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 172/ 292]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 173/ 292]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 174/ 292]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 175/ 292]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 176/ 292]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 177/ 292]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 178/ 292]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 179/ 292]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 180/ 292]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 181/ 292]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 182/ 292]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 183/ 292]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 184/ 292]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 185/ 292]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 186/ 292]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 187/ 292]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 188/ 292]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 189/ 292]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 190/ 292]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 191/ 292]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 192/ 292]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 193/ 292]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 194/ 292]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 195/ 292]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 196/ 292]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 197/ 292]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 198/ 292]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 199/ 292]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 200/ 292]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 201/ 292]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 202/ 292]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 203/ 292]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 204/ 292]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 205/ 292]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 206/ 292]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 207/ 292]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 208/ 292]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 209/ 292]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 210/ 292]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 211/ 292]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 212/ 292]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 213/ 292]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 214/ 292]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 215/ 292]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 216/ 292]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 217/ 292]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 218/ 292]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 219/ 292]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 220/ 292]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 221/ 292]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 222/ 292]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 223/ 292]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 224/ 292]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 225/ 292]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 226/ 292]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 227/ 292]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 228/ 292]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 229/ 292]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 230/ 292]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 231/ 292]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 232/ 292]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 233/ 292]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 234/ 292]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 235/ 292]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 236/ 292]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 237/ 292]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 238/ 292]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 239/ 292]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 240/ 292]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 241/ 292]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 242/ 292]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 243/ 292]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 244/ 292]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 245/ 292]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 246/ 292]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 247/ 292]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 248/ 292]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 249/ 292]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 250/ 292]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 251/ 292]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 252/ 292]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 253/ 292]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 254/ 292]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 255/ 292]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 256/ 292]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 257/ 292]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 258/ 292]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 259/ 292]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 260/ 292]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 261/ 292]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 262/ 292]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 263/ 292]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 264/ 292]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 265/ 292]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 266/ 292]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 267/ 292]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 268/ 292]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 269/ 292]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 270/ 292]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 271/ 292]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 272/ 292]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 273/ 292]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 274/ 292]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 275/ 292]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 276/ 292]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 277/ 292]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 278/ 292]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 279/ 292]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 280/ 292]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 281/ 292]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 282/ 292]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 283/ 292]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 284/ 292]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 285/ 292]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 286/ 292]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 287/ 292]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 288/ 292]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 289/ 292]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 290/ 292]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 291/ 292]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 292/ 292]                        output.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n","llama_model_quantize_internal: model size  = 15317.02 MB\n","llama_model_quantize_internal: quant size  =  4685.30 MB\n","\n","main: quantize time = 951948.80 ms\n","main:    total time = 951948.80 ms\n","Unsloth: Conversion completed! Output location: ./model/unsloth.Q4_K_M.gguf\n"]}],"source":["# Save to q4_k_m GGUF\n","if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")"]},{"cell_type":"markdown","metadata":{"id":"bDp0zNpwe6U_"},"source":["###Move GGUF to Google Drive"]},{"cell_type":"code","source":["!cp model/unsloth.Q4_K_M.gguf /content/drive/MyDrive/ds2-v5-llama3.1-8b-Q4_K_M.gguf"],"metadata":{"id":"COThzve0qyLB","executionInfo":{"status":"ok","timestamp":1723665494424,"user_tz":-120,"elapsed":68336,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"execution_count":12,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp","timestamp":1723403008292},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1721714808667},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"db49e49621574df8a520f89ebd3e9246":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98b7f22d0a0546a4ac0ddc5058e22a99","IPY_MODEL_0d65287653f04084b876fad7ee37de2d","IPY_MODEL_f943deaacfff400d9c0d0a6a7921d038"],"layout":"IPY_MODEL_95a586b379e843cca62f3a3ef6a68df8"}},"98b7f22d0a0546a4ac0ddc5058e22a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee56c03ac4ff4775976fd5d93aee4db3","placeholder":"â€‹","style":"IPY_MODEL_9d48ec1368c34bf18e48ace81ed09414","value":"model.safetensors:â€‡100%"}},"0d65287653f04084b876fad7ee37de2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d663962b8a7449ab104c2b861a467ad","max":5702746390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f757ed71584f449288f145e30d08be42","value":5702745847}},"f943deaacfff400d9c0d0a6a7921d038":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8167879135bd4fdb9513e523e7f06f37","placeholder":"â€‹","style":"IPY_MODEL_d820fbe9247c4bd8b3c533fc479e165f","value":"â€‡5.70G/5.70Gâ€‡[00:39&lt;00:00,â€‡202MB/s]"}},"95a586b379e843cca62f3a3ef6a68df8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee56c03ac4ff4775976fd5d93aee4db3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d48ec1368c34bf18e48ace81ed09414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d663962b8a7449ab104c2b861a467ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f757ed71584f449288f145e30d08be42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8167879135bd4fdb9513e523e7f06f37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d820fbe9247c4bd8b3c533fc479e165f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef384b1a06334cf699e9f160d5942b50":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9878fd6fadf6455698399e0e4c146eed","IPY_MODEL_c418c9d59ceb48e4944b189747494a90","IPY_MODEL_f3845f66a52f448dab3f18852c9bb3c7"],"layout":"IPY_MODEL_8c88907729dd46d6bfab905fc487f760"}},"9878fd6fadf6455698399e0e4c146eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e3b21960b1d40eea9d4d550baacdae1","placeholder":"â€‹","style":"IPY_MODEL_992307ef82e34dad800c2be62cd60bd7","value":"generation_config.json:â€‡100%"}},"c418c9d59ceb48e4944b189747494a90":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0594694eb2474ad581b8be7c1b01c12c","max":230,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f27725a5fff64522adc9bd86e75454fa","value":230}},"f3845f66a52f448dab3f18852c9bb3c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47eada1597fe4bb898d102ed168d355b","placeholder":"â€‹","style":"IPY_MODEL_b9d6c9cec73a4e6d94ebaab5c0ef6824","value":"â€‡230/230â€‡[00:00&lt;00:00,â€‡8.61kB/s]"}},"8c88907729dd46d6bfab905fc487f760":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3b21960b1d40eea9d4d550baacdae1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"992307ef82e34dad800c2be62cd60bd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0594694eb2474ad581b8be7c1b01c12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27725a5fff64522adc9bd86e75454fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47eada1597fe4bb898d102ed168d355b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9d6c9cec73a4e6d94ebaab5c0ef6824":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52b141f2c1f64f9789879ebd0b06e0e9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_135f37244033443eb4b10b68e269dc33","IPY_MODEL_d0e32721f8cd4852ba61fa8dec933a31","IPY_MODEL_05369cc8af714b638ed996fea3cca420"],"layout":"IPY_MODEL_83bec57c9b054ddb8a4f182cc54b8583"}},"135f37244033443eb4b10b68e269dc33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_941551fd611a4ea996c73732eb2dfc63","placeholder":"â€‹","style":"IPY_MODEL_9e78525aea974b8fad268cdfec4a8e6e","value":"tokenizer_config.json:â€‡100%"}},"d0e32721f8cd4852ba61fa8dec933a31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebb91e90c83d4f5baf89c671f4517a75","max":50570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78d8e452884b4b098fe131badbbfe9b1","value":50570}},"05369cc8af714b638ed996fea3cca420":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75fd406c2ce841089f7e57605b8e6e8f","placeholder":"â€‹","style":"IPY_MODEL_9d0188395a7645b483253091d4dabf73","value":"â€‡50.6k/50.6kâ€‡[00:00&lt;00:00,â€‡3.27MB/s]"}},"83bec57c9b054ddb8a4f182cc54b8583":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"941551fd611a4ea996c73732eb2dfc63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e78525aea974b8fad268cdfec4a8e6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ebb91e90c83d4f5baf89c671f4517a75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78d8e452884b4b098fe131badbbfe9b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"75fd406c2ce841089f7e57605b8e6e8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d0188395a7645b483253091d4dabf73":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b308f492c43d4e2e99189ba631331ef5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9f382c4589b84312b79ead87857711fb","IPY_MODEL_9c67994d18ed45f48c042b77b858ddc8","IPY_MODEL_84c37d823e12413e8cc8891b1f83917c"],"layout":"IPY_MODEL_22e8e260223248b79b93986a66a050ae"}},"9f382c4589b84312b79ead87857711fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24e8118175ce48fe971f5948a83aa398","placeholder":"â€‹","style":"IPY_MODEL_b56bab12033745e980866d1bd17878e7","value":"tokenizer.json:â€‡100%"}},"9c67994d18ed45f48c042b77b858ddc8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03dd14ebd205437cb6e1e647425aa93c","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf36697d04884db4b5ae3e4a0f8b8a68","value":9085657}},"84c37d823e12413e8cc8891b1f83917c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5de4bf9140cf4b7ca538d8062f73d884","placeholder":"â€‹","style":"IPY_MODEL_eebcc86a49ca4512af63f385fa75f04f","value":"â€‡9.09M/9.09Mâ€‡[00:01&lt;00:00,â€‡6.01MB/s]"}},"22e8e260223248b79b93986a66a050ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24e8118175ce48fe971f5948a83aa398":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b56bab12033745e980866d1bd17878e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03dd14ebd205437cb6e1e647425aa93c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf36697d04884db4b5ae3e4a0f8b8a68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5de4bf9140cf4b7ca538d8062f73d884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eebcc86a49ca4512af63f385fa75f04f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2cdbf98d1384d5dadf70a110a8e4839":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c02eef0320ee4d488717cffc287871b0","IPY_MODEL_8dc0788c5cf64cb894973e8d1708a3a4","IPY_MODEL_c9dd53d0427442baa943920681eebe1d"],"layout":"IPY_MODEL_19da87e24e434711a9933d33db06cf75"}},"c02eef0320ee4d488717cffc287871b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9d88c6eee64452d9c3d161f1e2aceba","placeholder":"â€‹","style":"IPY_MODEL_714da808fb4840198634b599a89c1d28","value":"special_tokens_map.json:â€‡100%"}},"8dc0788c5cf64cb894973e8d1708a3a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af54793e5b9243dba802da7302c40b14","max":345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da76e3ccbc29436489a02219201ff24f","value":345}},"c9dd53d0427442baa943920681eebe1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89fa660be9e0492b9002defdb6757676","placeholder":"â€‹","style":"IPY_MODEL_a9f1584681a6408bac3e2c76aaed8322","value":"â€‡345/345â€‡[00:00&lt;00:00,â€‡25.8kB/s]"}},"19da87e24e434711a9933d33db06cf75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9d88c6eee64452d9c3d161f1e2aceba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714da808fb4840198634b599a89c1d28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af54793e5b9243dba802da7302c40b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da76e3ccbc29436489a02219201ff24f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89fa660be9e0492b9002defdb6757676":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9f1584681a6408bac3e2c76aaed8322":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"033b491ec3fb40bcb4cf91da5dd6219d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9c2a8d13f6a4f35b6571ae875e64b18","IPY_MODEL_b9ca0f86db2a4f77a8d4ae799e6a975e","IPY_MODEL_236fadb1927e40caa5f9162afdf12e48"],"layout":"IPY_MODEL_8d770542415a448f999dd864aee21492"}},"b9c2a8d13f6a4f35b6571ae875e64b18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11ffc9b7d20e4c198c3f414d9fe22d82","placeholder":"â€‹","style":"IPY_MODEL_df802bc79ef34c82a5b697519bacb5b3","value":"Generatingâ€‡trainâ€‡split:â€‡"}},"b9ca0f86db2a4f77a8d4ae799e6a975e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d7a2cdbbe01479aa85fc1c9b4d1e76c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52579aab9b5c458594f8bac3783f3abf","value":1}},"236fadb1927e40caa5f9162afdf12e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38c4f3e358a64ef8a0c5a5620835a114","placeholder":"â€‹","style":"IPY_MODEL_350424ff7a3149f395bb621542d39477","value":"â€‡1000/0â€‡[00:00&lt;00:00,â€‡1076.21â€‡examples/s]"}},"8d770542415a448f999dd864aee21492":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11ffc9b7d20e4c198c3f414d9fe22d82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df802bc79ef34c82a5b697519bacb5b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d7a2cdbbe01479aa85fc1c9b4d1e76c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"52579aab9b5c458594f8bac3783f3abf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38c4f3e358a64ef8a0c5a5620835a114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"350424ff7a3149f395bb621542d39477":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c09ef097d4041baa61b43c4fc981ead":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7c4e2123ae943b9b9bde4290bb77bd3","IPY_MODEL_b16f843c0c6c429090019bc1c9da967b","IPY_MODEL_fbffc27a3e16476ea4b6ba985c1abff8"],"layout":"IPY_MODEL_154a2b8b1bfb474889db22dae419572b"}},"e7c4e2123ae943b9b9bde4290bb77bd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4182623d1f634428885898ce12ce4b9f","placeholder":"â€‹","style":"IPY_MODEL_abec852a001d4642ae881cbb0413a646","value":"Map:â€‡100%"}},"b16f843c0c6c429090019bc1c9da967b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f626cd366948482c94851c3b7b9dade7","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f0f0d05514bd4e80a81de096000f019e","value":1000}},"fbffc27a3e16476ea4b6ba985c1abff8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcdc61982fcc41dea86949d799c64342","placeholder":"â€‹","style":"IPY_MODEL_08e2660c2263434a8bc2c65cde6cd8bf","value":"â€‡1000/1000â€‡[00:00&lt;00:00,â€‡11290.64â€‡examples/s]"}},"154a2b8b1bfb474889db22dae419572b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4182623d1f634428885898ce12ce4b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abec852a001d4642ae881cbb0413a646":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f626cd366948482c94851c3b7b9dade7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0f0d05514bd4e80a81de096000f019e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcdc61982fcc41dea86949d799c64342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08e2660c2263434a8bc2c65cde6cd8bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a3517bdbbba4fe38e6fa9a115d6bfe8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0892d88595164e9590fa448787d86391","IPY_MODEL_42de22b8125543968b38147d87950500","IPY_MODEL_936584ca18314bbba5caacea49413477"],"layout":"IPY_MODEL_2d2dde5adbc3452aa840c9b4e9d7d896"}},"0892d88595164e9590fa448787d86391":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81d5d844d37f479ab5c10b1cd8a088b1","placeholder":"â€‹","style":"IPY_MODEL_d5b533c8e33c4963a422a9812ab139c4","value":"Mapâ€‡(num_proc=2):â€‡100%"}},"42de22b8125543968b38147d87950500":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_928b74e3c5784c3697ae80a954c24524","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c7885180cd84afbbaf0cea5eeb856ab","value":1000}},"936584ca18314bbba5caacea49413477":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_350ed1178e5e4577ae6e6d1f4ed9e100","placeholder":"â€‹","style":"IPY_MODEL_3e3f97748a72473ba36e1c3f061b46ce","value":"â€‡1000/1000â€‡[00:05&lt;00:00,â€‡213.44â€‡examples/s]"}},"2d2dde5adbc3452aa840c9b4e9d7d896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d5d844d37f479ab5c10b1cd8a088b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5b533c8e33c4963a422a9812ab139c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"928b74e3c5784c3697ae80a954c24524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c7885180cd84afbbaf0cea5eeb856ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"350ed1178e5e4577ae6e6d1f4ed9e100":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e3f97748a72473ba36e1c3f061b46ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}