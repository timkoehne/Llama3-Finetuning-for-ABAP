{"cells":[{"cell_type":"markdown","source":["###Mount Google Drive"],"metadata":{"id":"JqnvfolnWK7v"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET9PkL1IqHZa","executionInfo":{"status":"ok","timestamp":1723569603022,"user_tz":-120,"elapsed":27156,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}},"outputId":"5654ec18-08b0-4325-a38e-3dcb4b24ef67"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["###Install dependencies\n","\n"],"metadata":{"id":"QzlXf98cWRxt"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"2eSvM9zX_2d3","executionInfo":{"status":"ok","timestamp":1723569653127,"user_tz":-120,"elapsed":50109,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[],"source":["%%capture\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"]},{"cell_type":"markdown","source":["###Create Model"],"metadata":{"id":"rEe3PMcDWYfA"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":302,"referenced_widgets":["a6afa99d17d645a888356b8cd7ddb457","a614ff38cf844ddbbf8cd345ae34cdb1","4699d11748624017acabf7b2e69a1d76","dad341b020f8439991193a7714a7c7e2","01ef7a2f2c3d4e9ab57c57a226147602","30e345ea99ed460da802e49af6b38456","b18d647d745d4adb8ae41b198ad82e2f","32560dbf548a48c29e30afe97748889e","4d550a9c2b3f44208070ae79deca44d0","949c218098c54728b7339189a5f6dd3a","4a8c203f55914c88b265b86e8e4aaf76","58b7a6e18a6a47baa4485469cbf9f919","c579e143292043d5bea207d1edf3b909","316de6478b3947078b6e257bbe0ee370","976992a37c114e9ebfc4415e64b75263","c47a66a45aa34c09b758a9fdacc6e7d8","7ae46477a0fc4e3aa7438141accd2b4e","def135759f334992a7d52a89a3f8bdf5","4b4c97db50794c3aaf2427b778104a84","af12d6f62b794d21b291e5c5e2be2185","013545c2bf98446dbdc4858c274491e1","e3018a06e5514e68944ff8d62d7b5889","f3a76a2f5b4c44b6977bff7ab3b6119c","6e0bcd6f62374f71aa3fe24e0794388d","e9e0144967bb481f8ada858410141d87","7248fb4880ff4d8089e13514a64051d6","58a1d45a74dd4a07b304280a3c771a34","15700054f4d944c89094fec4972ded4f","f7d91a975f7740ffbc3c9abb7fd5c84f","1e17f131341345d7989e1ddbd42c85bf","f818bcf31b8a48a6af6e552389bb3e7a","804ac61df3214c66815a96e9b46c40da","4d90b94160cd4e9e8e59373c7d24597c","1beca1aeb15a4b1d9a8223c850488b70","f2d454c5a5e9482eac69cc1b863fa166","718471fe4fd14827b1b7538ef34d9e30","ea0d895d360348b79a360a2cdf5f360e","ee96010baa9d4408928ded969b56d8bb","a8d20fc42b934beda0b011a325485d0c","4d8a3a6727f74beb99d2bc798ddd73b2","41ab07075fd34c81950e286d55f99773","8d6f3fc6d7044979954d35d1165a95b7","45a450ba946a4206ae885a0f90a31a38","d6fe98ac6ee64362b379e0b6a8cb77b0","1899c6e4e8844ffa9872f2239951445d","68fbcfa22db244148bd46d57555ff419","f22ed3310ae54b87aa63cb155a121e09","10b2aed2eae64d0ea39c91f248df29cd","62ac48e73c0b43d18ef99b8e5cff949e","15d55bdf892b4d6781a839673519b035","3af4fbaa9ab340a084c91024eb716e16","2851bddab1b54d32a601d83a4749a24a","34e88c925179421382fd717998f21df8","64b6be3b75ab4926b4c88cc239b57e17","9e7cbdd6d3d64d13bf52a52044bc0e29"]},"executionInfo":{"elapsed":104602,"status":"ok","timestamp":1723569757718,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"QmUBVEnvCDJv","outputId":"b811426f-fe2f-4495-8ab9-ccdd27fd9c6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n","   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6afa99d17d645a888356b8cd7ddb457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b7a6e18a6a47baa4485469cbf9f919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3a76a2f5b4c44b6977bff7ab3b6119c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1beca1aeb15a4b1d9a8223c850488b70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1899c6e4e8844ffa9872f2239951445d"}},"metadata":{}}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 8192 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["###Add LoRA adapters"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7254,"status":"ok","timestamp":1723569764964,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"6bZsfBuZDeCL","outputId":"0479cad8-c2cd-451c-f877-8a57116be84a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"markdown","metadata":{"id":"vITh0KVJ10qX"},"source":["<a name=\"Data\"></a>\n","### Data Prep\n","\n","**[NOTE]** Remember to add the **EOS_TOKEN** to the tokenized output!! Otherwise you'll get infinite generations!"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1207,"status":"ok","timestamp":1723569766164,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"LjY75GoYUCB8","colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["9ecfd4b74bf84d78a8fa9cbd361c1d8a","99d810f9e1b94a86ab208c73e6e54433","834067237bc843ff87dba8aff6725b26","d77fcc417a0a4ca7bae23bb68ce0ff8a","1bd1ee6fd93347d989ed88096ee8841c","5516bc220b754979ba8f1fa1aeb91f7f","248feeebe6134eceb49abb90e508aa26","3e348de068104a20b3bdcef3425a579b","d0ffdd00063a4f759da25a528633126e","98ae9874aa934166b72617cdaa3181f2","7d40221ae7d84798a4ee1a2ba43fcf01","063b7e1868054551867769ea11f8cf57","8e7f961a82c04e269c9690a3cd8550cb","6f9acddcab234887a195611032c6000c","d14619edcf4d4c89b1067323bf8571d1","14f05276e051472fb2946346e2fb288d","abd85ca20d474b5b98854f6c17e0468b","4ef9cf759ab14f428e768a66a96b3782","5da6bd4049954538b42b6c5b72177428","708fa3faaef54b9ca55bcb60186c739f","67f43945626c4f2d92ad02df4ef90f1a","80b4ece897024d608cd3abe3bba7e8ca"]},"outputId":"3b9fe817-2a9d-411e-ad21-0e804b770a33"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ecfd4b74bf84d78a8fa9cbd361c1d8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/248 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"063b7e1868054551867769ea11f8cf57"}},"metadata":{}}],"source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","{}\n","\n","### Response:\n","```abap\n","{}\n","```\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"prompt\"]\n","    outputs      = examples[\"response\"]\n","    texts = []\n","    for instruction, output in zip(instructions, outputs):\n","        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n","        text = alpaca_prompt.format(instruction, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass\n","\n","from datasets import load_dataset\n","dataset = load_dataset(\"json\", data_files='/content/drive/MyDrive/DS3.json', split=\"train\")\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Training the model"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6405,"status":"ok","timestamp":1723569772565,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"95_Nn-89DhsL","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["7f40a7dcff6e4f3cb2ca4934a4daacdf","ba2b964b82284a07baa699e3bf250d4f","1e842c73c72d456bb99d3f3ee3a9b11f","2966aaaa63cc481e85d5d34c0d72bae5","989bcaf1851f425ca8c07e0952964163","dfccea4537664ede9d9efffc1874f058","1b0fb46ed5a4459296b8ca09d931b461","8686e9dce9fd4d05bbcb3a40653ae811","e8b283713df54d6b865f166d8a60120a","0c9064e55ded4ad5b63e41790683f7cf","446445e44bd34e68a41b69847cce5024"]},"outputId":"3de8bf15-6941-484c-f99a-c55c9a9df6cd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Map (num_proc=2):   0%|          | 0/248 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f40a7dcff6e4f3cb2ca4934a4daacdf"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 5,\n","        num_train_epochs = 10,\n","        max_steps = -1,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = 1,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"linear\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1723569772565,"user":{"displayName":"Tim K.","userId":"15418474976637013045"},"user_tz":-120},"id":"2ejIt2xSNKKp","outputId":"d254f53b-85e9-4b30-9369-51c64363bfd6","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = Tesla T4. Max memory = 14.748 GB.\n","5.984 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"yqxqAZ7KJ4oL","outputId":"c386a60f-4d91-4862-d86b-10fed6c27bb1","executionInfo":{"status":"ok","timestamp":1723571750906,"user_tz":-120,"elapsed":1978345,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 248 | Num Epochs = 10\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 310\n"," \"-____-\"     Number of trainable parameters = 41,943,040\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='310' max='310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [310/310 32:36, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.414100</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.385800</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.376000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.252500</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.003800</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.955900</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.655100</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.500600</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.361900</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.286700</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.258300</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.340400</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.230700</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.268100</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.228700</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.155900</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.182600</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.205700</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.161600</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.177300</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>0.167600</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>0.274000</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>0.126500</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>0.190500</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>0.170200</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>0.093100</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>0.165400</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>0.156600</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>0.129600</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>0.164200</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>0.157100</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>0.114600</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>0.124100</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>0.092800</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>0.113800</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>0.095000</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>0.098300</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>0.110700</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>0.151300</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>0.111700</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>0.077700</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>0.107900</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>0.112500</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>0.077300</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>0.109800</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>0.107800</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>0.101100</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>0.101000</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>0.109400</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>0.091500</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>0.131600</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>0.113100</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>0.135400</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>0.111100</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>0.131400</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>0.086800</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>0.125100</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>0.137900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>0.142500</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>0.093600</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>0.102300</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>0.086400</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>0.103400</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>0.081000</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>0.068300</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>0.101300</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>0.097600</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>0.084600</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>0.079900</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>0.075600</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>0.089000</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>0.099500</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>0.077700</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>0.082400</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>0.082300</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>0.084900</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>0.091800</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>0.084600</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>0.082000</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>0.082900</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>0.083300</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>0.088300</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>0.087700</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>0.087300</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>0.080300</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>0.084100</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>0.082900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>0.097100</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>0.100800</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>0.068300</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>0.081600</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>0.065900</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>0.076300</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>0.071100</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>0.082700</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>0.097700</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>0.075300</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.063500</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>0.080600</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>0.069200</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>0.068800</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>0.078600</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>0.067700</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>0.075100</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>0.058900</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>0.076000</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>0.076000</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>0.067100</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>0.075300</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>0.078700</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>0.066700</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>0.083600</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>0.068900</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>0.084400</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>0.082800</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>0.076600</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>0.078000</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>0.081900</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>0.079600</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>0.085100</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>0.080900</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.069500</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>0.061000</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>0.061700</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>0.075500</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>0.072100</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>0.067600</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>0.064600</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>0.070000</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>0.075800</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>0.067300</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>0.074000</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>0.057600</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>0.072700</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>0.065700</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>0.073800</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>0.064900</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>0.056500</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>0.067200</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>0.064700</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>0.063900</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>0.076100</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.071800</td>\n","    </tr>\n","    <tr>\n","      <td>151</td>\n","      <td>0.064100</td>\n","    </tr>\n","    <tr>\n","      <td>152</td>\n","      <td>0.081300</td>\n","    </tr>\n","    <tr>\n","      <td>153</td>\n","      <td>0.065300</td>\n","    </tr>\n","    <tr>\n","      <td>154</td>\n","      <td>0.070400</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>0.058200</td>\n","    </tr>\n","    <tr>\n","      <td>156</td>\n","      <td>0.056000</td>\n","    </tr>\n","    <tr>\n","      <td>157</td>\n","      <td>0.061300</td>\n","    </tr>\n","    <tr>\n","      <td>158</td>\n","      <td>0.052800</td>\n","    </tr>\n","    <tr>\n","      <td>159</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>0.052100</td>\n","    </tr>\n","    <tr>\n","      <td>161</td>\n","      <td>0.051100</td>\n","    </tr>\n","    <tr>\n","      <td>162</td>\n","      <td>0.056200</td>\n","    </tr>\n","    <tr>\n","      <td>163</td>\n","      <td>0.070800</td>\n","    </tr>\n","    <tr>\n","      <td>164</td>\n","      <td>0.062100</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>166</td>\n","      <td>0.061800</td>\n","    </tr>\n","    <tr>\n","      <td>167</td>\n","      <td>0.062600</td>\n","    </tr>\n","    <tr>\n","      <td>168</td>\n","      <td>0.069100</td>\n","    </tr>\n","    <tr>\n","      <td>169</td>\n","      <td>0.053500</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>0.059300</td>\n","    </tr>\n","    <tr>\n","      <td>171</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>172</td>\n","      <td>0.055600</td>\n","    </tr>\n","    <tr>\n","      <td>173</td>\n","      <td>0.057100</td>\n","    </tr>\n","    <tr>\n","      <td>174</td>\n","      <td>0.063700</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.073800</td>\n","    </tr>\n","    <tr>\n","      <td>176</td>\n","      <td>0.059600</td>\n","    </tr>\n","    <tr>\n","      <td>177</td>\n","      <td>0.051000</td>\n","    </tr>\n","    <tr>\n","      <td>178</td>\n","      <td>0.063300</td>\n","    </tr>\n","    <tr>\n","      <td>179</td>\n","      <td>0.056800</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>181</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>182</td>\n","      <td>0.070400</td>\n","    </tr>\n","    <tr>\n","      <td>183</td>\n","      <td>0.059400</td>\n","    </tr>\n","    <tr>\n","      <td>184</td>\n","      <td>0.073100</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>0.063800</td>\n","    </tr>\n","    <tr>\n","      <td>186</td>\n","      <td>0.057800</td>\n","    </tr>\n","    <tr>\n","      <td>187</td>\n","      <td>0.052000</td>\n","    </tr>\n","    <tr>\n","      <td>188</td>\n","      <td>0.047300</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>0.054100</td>\n","    </tr>\n","    <tr>\n","      <td>191</td>\n","      <td>0.056100</td>\n","    </tr>\n","    <tr>\n","      <td>192</td>\n","      <td>0.056600</td>\n","    </tr>\n","    <tr>\n","      <td>193</td>\n","      <td>0.059200</td>\n","    </tr>\n","    <tr>\n","      <td>194</td>\n","      <td>0.055100</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>0.057000</td>\n","    </tr>\n","    <tr>\n","      <td>196</td>\n","      <td>0.053800</td>\n","    </tr>\n","    <tr>\n","      <td>197</td>\n","      <td>0.054400</td>\n","    </tr>\n","    <tr>\n","      <td>198</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>199</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>201</td>\n","      <td>0.054200</td>\n","    </tr>\n","    <tr>\n","      <td>202</td>\n","      <td>0.054600</td>\n","    </tr>\n","    <tr>\n","      <td>203</td>\n","      <td>0.055000</td>\n","    </tr>\n","    <tr>\n","      <td>204</td>\n","      <td>0.048800</td>\n","    </tr>\n","    <tr>\n","      <td>205</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>206</td>\n","      <td>0.055200</td>\n","    </tr>\n","    <tr>\n","      <td>207</td>\n","      <td>0.063200</td>\n","    </tr>\n","    <tr>\n","      <td>208</td>\n","      <td>0.053100</td>\n","    </tr>\n","    <tr>\n","      <td>209</td>\n","      <td>0.070100</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>0.057900</td>\n","    </tr>\n","    <tr>\n","      <td>211</td>\n","      <td>0.056200</td>\n","    </tr>\n","    <tr>\n","      <td>212</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>213</td>\n","      <td>0.064200</td>\n","    </tr>\n","    <tr>\n","      <td>214</td>\n","      <td>0.064400</td>\n","    </tr>\n","    <tr>\n","      <td>215</td>\n","      <td>0.057600</td>\n","    </tr>\n","    <tr>\n","      <td>216</td>\n","      <td>0.061600</td>\n","    </tr>\n","    <tr>\n","      <td>217</td>\n","      <td>0.060700</td>\n","    </tr>\n","    <tr>\n","      <td>218</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>219</td>\n","      <td>0.056000</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>221</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>222</td>\n","      <td>0.051400</td>\n","    </tr>\n","    <tr>\n","      <td>223</td>\n","      <td>0.047200</td>\n","    </tr>\n","    <tr>\n","      <td>224</td>\n","      <td>0.053600</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>0.056400</td>\n","    </tr>\n","    <tr>\n","      <td>226</td>\n","      <td>0.050200</td>\n","    </tr>\n","    <tr>\n","      <td>227</td>\n","      <td>0.048600</td>\n","    </tr>\n","    <tr>\n","      <td>228</td>\n","      <td>0.050300</td>\n","    </tr>\n","    <tr>\n","      <td>229</td>\n","      <td>0.046300</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>0.050300</td>\n","    </tr>\n","    <tr>\n","      <td>231</td>\n","      <td>0.056700</td>\n","    </tr>\n","    <tr>\n","      <td>232</td>\n","      <td>0.053200</td>\n","    </tr>\n","    <tr>\n","      <td>233</td>\n","      <td>0.050500</td>\n","    </tr>\n","    <tr>\n","      <td>234</td>\n","      <td>0.064500</td>\n","    </tr>\n","    <tr>\n","      <td>235</td>\n","      <td>0.057300</td>\n","    </tr>\n","    <tr>\n","      <td>236</td>\n","      <td>0.051300</td>\n","    </tr>\n","    <tr>\n","      <td>237</td>\n","      <td>0.049600</td>\n","    </tr>\n","    <tr>\n","      <td>238</td>\n","      <td>0.054000</td>\n","    </tr>\n","    <tr>\n","      <td>239</td>\n","      <td>0.054500</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>241</td>\n","      <td>0.055800</td>\n","    </tr>\n","    <tr>\n","      <td>242</td>\n","      <td>0.041400</td>\n","    </tr>\n","    <tr>\n","      <td>243</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>244</td>\n","      <td>0.056500</td>\n","    </tr>\n","    <tr>\n","      <td>245</td>\n","      <td>0.058600</td>\n","    </tr>\n","    <tr>\n","      <td>246</td>\n","      <td>0.053300</td>\n","    </tr>\n","    <tr>\n","      <td>247</td>\n","      <td>0.056300</td>\n","    </tr>\n","    <tr>\n","      <td>248</td>\n","      <td>0.052400</td>\n","    </tr>\n","    <tr>\n","      <td>249</td>\n","      <td>0.044900</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>251</td>\n","      <td>0.046000</td>\n","    </tr>\n","    <tr>\n","      <td>252</td>\n","      <td>0.041600</td>\n","    </tr>\n","    <tr>\n","      <td>253</td>\n","      <td>0.043200</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>0.039000</td>\n","    </tr>\n","    <tr>\n","      <td>255</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>256</td>\n","      <td>0.048000</td>\n","    </tr>\n","    <tr>\n","      <td>257</td>\n","      <td>0.049200</td>\n","    </tr>\n","    <tr>\n","      <td>258</td>\n","      <td>0.039400</td>\n","    </tr>\n","    <tr>\n","      <td>259</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>0.051600</td>\n","    </tr>\n","    <tr>\n","      <td>261</td>\n","      <td>0.045100</td>\n","    </tr>\n","    <tr>\n","      <td>262</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>263</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>264</td>\n","      <td>0.044400</td>\n","    </tr>\n","    <tr>\n","      <td>265</td>\n","      <td>0.051500</td>\n","    </tr>\n","    <tr>\n","      <td>266</td>\n","      <td>0.045800</td>\n","    </tr>\n","    <tr>\n","      <td>267</td>\n","      <td>0.050400</td>\n","    </tr>\n","    <tr>\n","      <td>268</td>\n","      <td>0.045900</td>\n","    </tr>\n","    <tr>\n","      <td>269</td>\n","      <td>0.051900</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>0.046100</td>\n","    </tr>\n","    <tr>\n","      <td>271</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>272</td>\n","      <td>0.049300</td>\n","    </tr>\n","    <tr>\n","      <td>273</td>\n","      <td>0.043700</td>\n","    </tr>\n","    <tr>\n","      <td>274</td>\n","      <td>0.058400</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>0.051800</td>\n","    </tr>\n","    <tr>\n","      <td>276</td>\n","      <td>0.048500</td>\n","    </tr>\n","    <tr>\n","      <td>277</td>\n","      <td>0.044200</td>\n","    </tr>\n","    <tr>\n","      <td>278</td>\n","      <td>0.051200</td>\n","    </tr>\n","    <tr>\n","      <td>279</td>\n","      <td>0.047900</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>0.042600</td>\n","    </tr>\n","    <tr>\n","      <td>281</td>\n","      <td>0.044600</td>\n","    </tr>\n","    <tr>\n","      <td>282</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>283</td>\n","      <td>0.042400</td>\n","    </tr>\n","    <tr>\n","      <td>284</td>\n","      <td>0.049400</td>\n","    </tr>\n","    <tr>\n","      <td>285</td>\n","      <td>0.038700</td>\n","    </tr>\n","    <tr>\n","      <td>286</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>287</td>\n","      <td>0.040300</td>\n","    </tr>\n","    <tr>\n","      <td>288</td>\n","      <td>0.038000</td>\n","    </tr>\n","    <tr>\n","      <td>289</td>\n","      <td>0.040100</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>291</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>292</td>\n","      <td>0.041000</td>\n","    </tr>\n","    <tr>\n","      <td>293</td>\n","      <td>0.048200</td>\n","    </tr>\n","    <tr>\n","      <td>294</td>\n","      <td>0.042200</td>\n","    </tr>\n","    <tr>\n","      <td>295</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>296</td>\n","      <td>0.046600</td>\n","    </tr>\n","    <tr>\n","      <td>297</td>\n","      <td>0.041200</td>\n","    </tr>\n","    <tr>\n","      <td>298</td>\n","      <td>0.042500</td>\n","    </tr>\n","    <tr>\n","      <td>299</td>\n","      <td>0.051700</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.047100</td>\n","    </tr>\n","    <tr>\n","      <td>301</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>302</td>\n","      <td>0.046800</td>\n","    </tr>\n","    <tr>\n","      <td>303</td>\n","      <td>0.046900</td>\n","    </tr>\n","    <tr>\n","      <td>304</td>\n","      <td>0.045000</td>\n","    </tr>\n","    <tr>\n","      <td>305</td>\n","      <td>0.042100</td>\n","    </tr>\n","    <tr>\n","      <td>306</td>\n","      <td>0.045600</td>\n","    </tr>\n","    <tr>\n","      <td>307</td>\n","      <td>0.042900</td>\n","    </tr>\n","    <tr>\n","      <td>308</td>\n","      <td>0.040800</td>\n","    </tr>\n","    <tr>\n","      <td>309</td>\n","      <td>0.045200</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>0.043000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"pCqnaKmlO1U9","executionInfo":{"status":"ok","timestamp":1723571750906,"user_tz":-120,"elapsed":6,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69d02de2-0fd9-4b62-a1e5-c524293b4f9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["1974.3307 seconds used for training.\n","32.91 minutes used for training.\n","Peak reserved memory = 6.801 GB.\n","Peak reserved memory for training = 0.817 GB.\n","Peak reserved memory % of max memory = 46.115 %.\n","Peak reserved memory for training % of max memory = 5.54 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"markdown","metadata":{"id":"uMuVrWbjAzhc"},"source":["<a name=\"Save\"></a>\n","### Save LoRA Adapter\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"upcOlWe7A1vc","outputId":"d58d0327-54de-4f8a-df95-9103348a0e73","executionInfo":{"status":"ok","timestamp":1723571754242,"user_tz":-120,"elapsed":3340,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"metadata":{},"execution_count":10}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")\n","# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n","# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"]},{"cell_type":"markdown","metadata":{"id":"TCv4vXHd61i7"},"source":["### GGUF / llama.cpp Conversion\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"FqfebeAdT073","executionInfo":{"status":"ok","timestamp":1723573398065,"user_tz":-120,"elapsed":1643827,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec058c82-68ce-48ba-ad95-3f6acb98c589"},"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n","We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n","To force `safe_serialization`, set it to `None` instead.\n","Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n","model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n","Unsloth: Will remove a cached repo with size 5.7G\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Merging 4bit and LoRA weights to 16bit...\n","Unsloth: Will use up to 6.54 out of 12.67 RAM for saving.\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 14/32 [00:01<00:01,  9.92it/s]We will save to Disk and not RAM now.\n","100%|██████████| 32/32 [01:26<00:00,  2.72s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Saving tokenizer... Done.\n","Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n","Unsloth: Saving model/pytorch_model-00001-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00002-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00003-of-00004.bin...\n","Unsloth: Saving model/pytorch_model-00004-of-00004.bin...\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Unsloth: Converting llama model. Can use fast conversion = False.\n"]},{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n","   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n","O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n","\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] will take 10 minutes each.\n"," \"-____-\"     In total, you will have to wait at least 16 minutes.\n","\n","Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n","Unsloth: [1] Converting model at model into f16 GGUF format.\n","The output location will be ./model/unsloth.F16.gguf\n","This will take 3 minutes...\n","INFO:hf-to-gguf:Loading model: model\n","INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n","INFO:hf-to-gguf:Exporting model...\n","INFO:hf-to-gguf:gguf: loading model weight map from 'pytorch_model.bin.index.json'\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00001-of-00004.bin'\n","INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 128256}\n","INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00002-of-00004.bin'\n","INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00003-of-00004.bin'\n","INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n","INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n","INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n","INFO:hf-to-gguf:gguf: loading model part 'pytorch_model-00004-of-00004.bin'\n","INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n","INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n","INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 128256}\n","INFO:hf-to-gguf:Set meta model\n","INFO:hf-to-gguf:Set model parameters\n","INFO:hf-to-gguf:gguf: context length = 131072\n","INFO:hf-to-gguf:gguf: embedding length = 4096\n","INFO:hf-to-gguf:gguf: feed forward length = 14336\n","INFO:hf-to-gguf:gguf: head count = 32\n","INFO:hf-to-gguf:gguf: key-value head count = 8\n","INFO:hf-to-gguf:gguf: rope theta = 500000.0\n","INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n","INFO:hf-to-gguf:gguf: file type = 1\n","INFO:hf-to-gguf:Set model tokenizer\n","INFO:gguf.vocab:Adding 280147 merge(s).\n","INFO:gguf.vocab:Setting special token type bos to 128000\n","INFO:gguf.vocab:Setting special token type eos to 128009\n","INFO:gguf.vocab:Setting special token type pad to 128004\n","INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n","{%- if custom_tools is defined %}\n","    {%- set tools = custom_tools %}\n","{%- endif %}\n","{%- if not tools_in_user_message is defined %}\n","    {%- set tools_in_user_message = true %}\n","{%- endif %}\n","{%- if not date_string is defined %}\n","    {%- set date_string = \"26 Jul 2024\" %}\n","{%- endif %}\n","{%- if not tools is defined %}\n","    {%- set tools = none %}\n","{%- endif %}\n","\n","{#- This block extracts the system message, so we can slot it into the right place. #}\n","{%- if messages[0]['role'] == 'system' %}\n","    {%- set system_message = messages[0]['content']|trim %}\n","    {%- set messages = messages[1:] %}\n","{%- else %}\n","    {%- set system_message = \"\" %}\n","{%- endif %}\n","\n","{#- System message + builtin tools #}\n","{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n","{%- if builtin_tools is defined or tools is not none %}\n","    {{- \"Environment: ipython\\n\" }}\n","{%- endif %}\n","{%- if builtin_tools is defined %}\n","    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n","{%- endif %}\n","{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n","{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n","{%- if tools is not none and not tools_in_user_message %}\n","    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n","    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n","    {{- \"Do not use variables.\\n\\n\" }}\n","    {%- for t in tools %}\n","        {{- t | tojson(indent=4) }}\n","        {{- \"\\n\\n\" }}\n","    {%- endfor %}\n","{%- endif %}\n","{{- system_message }}\n","{{- \"<|eot_id|>\" }}\n","\n","{#- Custom tools are passed in a user message with some extra guidance #}\n","{%- if tools_in_user_message and not tools is none %}\n","    {#- Extract the first user message so we can plug it in here #}\n","    {%- if messages | length != 0 %}\n","        {%- set first_user_message = messages[0]['content']|trim %}\n","        {%- set messages = messages[1:] %}\n","    {%- else %}\n","        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n","{%- endif %}\n","    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n","    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n","    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n","    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n","    {{- \"Do not use variables.\\n\\n\" }}\n","    {%- for t in tools %}\n","        {{- t | tojson(indent=4) }}\n","        {{- \"\\n\\n\" }}\n","    {%- endfor %}\n","    {{- first_user_message + \"<|eot_id|>\"}}\n","{%- endif %}\n","\n","{%- for message in messages %}\n","    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n","        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n","    {%- elif 'tool_calls' in message %}\n","        {%- if not message.tool_calls|length == 1 %}\n","            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n","        {%- endif %}\n","        {%- set tool_call = message.tool_calls[0].function %}\n","        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n","            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n","            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n","            {%- for arg_name, arg_val in tool_call.arguments | items %}\n","                {{- arg_name + '=\"' + arg_val + '\"' }}\n","                {%- if not loop.last %}\n","                    {{- \", \" }}\n","                {%- endif %}\n","                {%- endfor %}\n","            {{- \")\" }}\n","        {%- else  %}\n","            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n","            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n","            {{- '\"parameters\": ' }}\n","            {{- tool_call.arguments | tojson }}\n","            {{- \"}\" }}\n","        {%- endif %}\n","        {%- if builtin_tools is defined %}\n","            {#- This means we're in ipython mode #}\n","            {{- \"<|eom_id|>\" }}\n","        {%- else %}\n","            {{- \"<|eot_id|>\" }}\n","        {%- endif %}\n","    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n","        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n","        {%- if message.content is mapping or message.content is iterable %}\n","            {{- message.content | tojson }}\n","        {%- else %}\n","            {{- message.content }}\n","        {%- endif %}\n","        {{- \"<|eot_id|>\" }}\n","    {%- endif %}\n","{%- endfor %}\n","{%- if add_generation_prompt %}\n","    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n","{%- endif %}\n","\n","INFO:hf-to-gguf:Set model quantization version\n","INFO:gguf.gguf_writer:Writing the following files:\n","INFO:gguf.gguf_writer:model/unsloth.F16.gguf: n_tensors = 292, total_size = 16.1G\n","Writing: 100%|██████████| 16.1G/16.1G [03:02<00:00, 88.2Mbyte/s]\n","INFO:hf-to-gguf:Model successfully exported to model/unsloth.F16.gguf\n","Unsloth: Conversion completed! Output location: ./model/unsloth.F16.gguf\n","Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n","main: build = 3580 (828d6ff7)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing './model/unsloth.F16.gguf' to './model/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n","llama_model_loader: loaded meta data with 28 key-value pairs and 292 tensors from ./model/unsloth.F16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.type str              = model\n","llama_model_loader: - kv   2:                               general.name str              = Meta Llama 3.1 8b Instruct Bnb 4bit\n","llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n","llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n","llama_model_loader: - kv   5:                           general.basename str              = meta-llama-3.1\n","llama_model_loader: - kv   6:                         general.size_label str              = 8B\n","llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n","llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n","llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n","llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n","llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  15:                          general.file_type u32              = 1\n","llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n","llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n","llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n","llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n","llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n","llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n","llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n","llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n","llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n","llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n","llama_model_loader: - kv  27:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   66 tensors\n","llama_model_loader: - type  f16:  226 tensors\n","[   1/ 292]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n","[   2/ 292]                    token_embd.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n","[   3/ 292]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[   4/ 292]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[   5/ 292]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[   6/ 292]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[   7/ 292]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[   8/ 292]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[   9/ 292]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  10/ 292]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  11/ 292]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  12/ 292]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  13/ 292]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  14/ 292]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  15/ 292]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  16/ 292]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  17/ 292]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  18/ 292]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  19/ 292]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  20/ 292]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  21/ 292]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  22/ 292]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  23/ 292]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  24/ 292]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  25/ 292]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  26/ 292]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  27/ 292]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  28/ 292]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  29/ 292]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  30/ 292]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  31/ 292]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  32/ 292]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  33/ 292]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  34/ 292]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  35/ 292]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  36/ 292]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  37/ 292]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  38/ 292]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  39/ 292]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  40/ 292]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  41/ 292]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  42/ 292]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  43/ 292]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  44/ 292]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  45/ 292]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  46/ 292]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  47/ 292]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  48/ 292]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  49/ 292]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  50/ 292]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  51/ 292]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  52/ 292]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  53/ 292]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  54/ 292]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  55/ 292]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  56/ 292]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  57/ 292]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  58/ 292]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  59/ 292]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  60/ 292]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  61/ 292]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  62/ 292]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  63/ 292]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  64/ 292]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  65/ 292]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  66/ 292]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  67/ 292]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  68/ 292]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  69/ 292]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  70/ 292]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  71/ 292]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  72/ 292]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  73/ 292]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  74/ 292]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  75/ 292]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  76/ 292]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  77/ 292]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  78/ 292]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  79/ 292]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  80/ 292]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  81/ 292]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  82/ 292]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  83/ 292]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  84/ 292]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  85/ 292]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  86/ 292]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[  87/ 292]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  88/ 292]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  89/ 292]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  90/ 292]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[  91/ 292]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  92/ 292]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  93/ 292]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  94/ 292]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  95/ 292]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[  96/ 292]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  97/ 292]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  98/ 292]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[  99/ 292]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 100/ 292]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 101/ 292]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 102/ 292]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 103/ 292]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 104/ 292]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 105/ 292]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 106/ 292]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 107/ 292]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 108/ 292]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 109/ 292]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 110/ 292]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 111/ 292]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 112/ 292]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 113/ 292]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 114/ 292]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 115/ 292]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 116/ 292]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 117/ 292]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 118/ 292]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 119/ 292]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 120/ 292]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 121/ 292]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 122/ 292]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 123/ 292]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 124/ 292]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 125/ 292]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 126/ 292]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 127/ 292]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 128/ 292]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 129/ 292]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 130/ 292]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 131/ 292]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 132/ 292]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 133/ 292]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 134/ 292]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 135/ 292]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 136/ 292]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 137/ 292]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 138/ 292]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 139/ 292]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 140/ 292]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 141/ 292]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 142/ 292]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 143/ 292]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 144/ 292]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 145/ 292]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 146/ 292]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 147/ 292]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 148/ 292]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 149/ 292]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 150/ 292]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 151/ 292]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 152/ 292]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 153/ 292]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 154/ 292]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 155/ 292]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 156/ 292]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 157/ 292]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 158/ 292]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 159/ 292]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 160/ 292]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 161/ 292]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 162/ 292]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 163/ 292]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 164/ 292]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 165/ 292]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 166/ 292]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 167/ 292]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 168/ 292]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 169/ 292]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 170/ 292]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 171/ 292]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 172/ 292]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 173/ 292]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 174/ 292]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 175/ 292]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 176/ 292]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 177/ 292]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 178/ 292]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 179/ 292]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 180/ 292]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 181/ 292]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 182/ 292]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 183/ 292]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 184/ 292]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 185/ 292]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 186/ 292]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 187/ 292]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 188/ 292]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 189/ 292]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 190/ 292]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 191/ 292]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 192/ 292]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 193/ 292]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 194/ 292]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 195/ 292]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 196/ 292]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 197/ 292]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 198/ 292]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 199/ 292]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 200/ 292]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 201/ 292]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 202/ 292]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 203/ 292]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 204/ 292]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 205/ 292]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 206/ 292]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 207/ 292]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 208/ 292]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 209/ 292]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 210/ 292]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 211/ 292]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 212/ 292]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 213/ 292]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 214/ 292]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 215/ 292]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 216/ 292]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 217/ 292]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 218/ 292]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 219/ 292]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 220/ 292]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 221/ 292]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 222/ 292]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 223/ 292]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 224/ 292]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 225/ 292]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 226/ 292]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 227/ 292]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 228/ 292]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 229/ 292]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 230/ 292]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 231/ 292]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 232/ 292]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 233/ 292]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 234/ 292]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 235/ 292]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 236/ 292]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 237/ 292]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 238/ 292]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 239/ 292]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 240/ 292]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 241/ 292]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 242/ 292]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 243/ 292]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 244/ 292]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 245/ 292]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 246/ 292]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 247/ 292]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 248/ 292]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 249/ 292]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 250/ 292]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 251/ 292]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 252/ 292]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 253/ 292]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 254/ 292]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 255/ 292]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 256/ 292]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 257/ 292]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 258/ 292]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 259/ 292]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 260/ 292]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 261/ 292]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 262/ 292]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 263/ 292]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 264/ 292]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 265/ 292]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 266/ 292]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 267/ 292]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 268/ 292]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 269/ 292]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 270/ 292]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 271/ 292]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 272/ 292]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 273/ 292]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 274/ 292]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 275/ 292]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 276/ 292]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 277/ 292]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 278/ 292]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 279/ 292]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 280/ 292]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 281/ 292]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 282/ 292]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 283/ 292]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n","[ 284/ 292]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n","[ 285/ 292]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 286/ 292]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 287/ 292]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n","[ 288/ 292]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n","[ 289/ 292]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 290/ 292]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 291/ 292]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 292/ 292]                        output.weight - [ 4096, 128256,     1,     1], type =    f16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n","llama_model_quantize_internal: model size  = 15317.02 MB\n","llama_model_quantize_internal: quant size  =  4685.30 MB\n","\n","main: quantize time = 952890.13 ms\n","main:    total time = 952890.13 ms\n","Unsloth: Conversion completed! Output location: ./model/unsloth.Q4_K_M.gguf\n"]}],"source":["# Save to q4_k_m GGUF\n","if True: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")"]},{"cell_type":"markdown","source":["###Move GGUF to Google Drive"],"metadata":{"id":"Mc4JJ6GxVLOM"}},{"cell_type":"code","source":["!cp model/unsloth.Q4_K_M.gguf /content/drive/MyDrive/ds3-v3-llama3.1-8b-Q4_K_M.gguf"],"metadata":{"id":"gE1bEIQQH_2L","executionInfo":{"status":"ok","timestamp":1723573462110,"user_tz":-120,"elapsed":64052,"user":{"displayName":"Tim K.","userId":"15418474976637013045"}}},"execution_count":12,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp","timestamp":1723377933769},{"file_id":"135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp","timestamp":1721714808667},{"file_id":"10NbwlsRChbma1v55m8LAPYG15uQv6HLo","timestamp":1713459337061},{"file_id":"1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_","timestamp":1708958229810},{"file_id":"1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5","timestamp":1703608159823},{"file_id":"1oW55fBmwzCOrBVX66RcpptL3a99qWBxb","timestamp":1702886138876}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a6afa99d17d645a888356b8cd7ddb457":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a614ff38cf844ddbbf8cd345ae34cdb1","IPY_MODEL_4699d11748624017acabf7b2e69a1d76","IPY_MODEL_dad341b020f8439991193a7714a7c7e2"],"layout":"IPY_MODEL_01ef7a2f2c3d4e9ab57c57a226147602"}},"a614ff38cf844ddbbf8cd345ae34cdb1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e345ea99ed460da802e49af6b38456","placeholder":"​","style":"IPY_MODEL_b18d647d745d4adb8ae41b198ad82e2f","value":"model.safetensors: 100%"}},"4699d11748624017acabf7b2e69a1d76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_32560dbf548a48c29e30afe97748889e","max":5702746383,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d550a9c2b3f44208070ae79deca44d0","value":5702745840}},"dad341b020f8439991193a7714a7c7e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_949c218098c54728b7339189a5f6dd3a","placeholder":"​","style":"IPY_MODEL_4a8c203f55914c88b265b86e8e4aaf76","value":" 5.70G/5.70G [00:46&lt;00:00, 107MB/s]"}},"01ef7a2f2c3d4e9ab57c57a226147602":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30e345ea99ed460da802e49af6b38456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b18d647d745d4adb8ae41b198ad82e2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32560dbf548a48c29e30afe97748889e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d550a9c2b3f44208070ae79deca44d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"949c218098c54728b7339189a5f6dd3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a8c203f55914c88b265b86e8e4aaf76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58b7a6e18a6a47baa4485469cbf9f919":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c579e143292043d5bea207d1edf3b909","IPY_MODEL_316de6478b3947078b6e257bbe0ee370","IPY_MODEL_976992a37c114e9ebfc4415e64b75263"],"layout":"IPY_MODEL_c47a66a45aa34c09b758a9fdacc6e7d8"}},"c579e143292043d5bea207d1edf3b909":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ae46477a0fc4e3aa7438141accd2b4e","placeholder":"​","style":"IPY_MODEL_def135759f334992a7d52a89a3f8bdf5","value":"generation_config.json: 100%"}},"316de6478b3947078b6e257bbe0ee370":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b4c97db50794c3aaf2427b778104a84","max":234,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af12d6f62b794d21b291e5c5e2be2185","value":234}},"976992a37c114e9ebfc4415e64b75263":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_013545c2bf98446dbdc4858c274491e1","placeholder":"​","style":"IPY_MODEL_e3018a06e5514e68944ff8d62d7b5889","value":" 234/234 [00:00&lt;00:00, 14.5kB/s]"}},"c47a66a45aa34c09b758a9fdacc6e7d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ae46477a0fc4e3aa7438141accd2b4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"def135759f334992a7d52a89a3f8bdf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b4c97db50794c3aaf2427b778104a84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af12d6f62b794d21b291e5c5e2be2185":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"013545c2bf98446dbdc4858c274491e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3018a06e5514e68944ff8d62d7b5889":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3a76a2f5b4c44b6977bff7ab3b6119c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6e0bcd6f62374f71aa3fe24e0794388d","IPY_MODEL_e9e0144967bb481f8ada858410141d87","IPY_MODEL_7248fb4880ff4d8089e13514a64051d6"],"layout":"IPY_MODEL_58a1d45a74dd4a07b304280a3c771a34"}},"6e0bcd6f62374f71aa3fe24e0794388d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15700054f4d944c89094fec4972ded4f","placeholder":"​","style":"IPY_MODEL_f7d91a975f7740ffbc3c9abb7fd5c84f","value":"tokenizer_config.json: 100%"}},"e9e0144967bb481f8ada858410141d87":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e17f131341345d7989e1ddbd42c85bf","max":55421,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f818bcf31b8a48a6af6e552389bb3e7a","value":55421}},"7248fb4880ff4d8089e13514a64051d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_804ac61df3214c66815a96e9b46c40da","placeholder":"​","style":"IPY_MODEL_4d90b94160cd4e9e8e59373c7d24597c","value":" 55.4k/55.4k [00:00&lt;00:00, 3.67MB/s]"}},"58a1d45a74dd4a07b304280a3c771a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15700054f4d944c89094fec4972ded4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d91a975f7740ffbc3c9abb7fd5c84f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e17f131341345d7989e1ddbd42c85bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f818bcf31b8a48a6af6e552389bb3e7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"804ac61df3214c66815a96e9b46c40da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d90b94160cd4e9e8e59373c7d24597c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1beca1aeb15a4b1d9a8223c850488b70":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2d454c5a5e9482eac69cc1b863fa166","IPY_MODEL_718471fe4fd14827b1b7538ef34d9e30","IPY_MODEL_ea0d895d360348b79a360a2cdf5f360e"],"layout":"IPY_MODEL_ee96010baa9d4408928ded969b56d8bb"}},"f2d454c5a5e9482eac69cc1b863fa166":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8d20fc42b934beda0b011a325485d0c","placeholder":"​","style":"IPY_MODEL_4d8a3a6727f74beb99d2bc798ddd73b2","value":"tokenizer.json: 100%"}},"718471fe4fd14827b1b7538ef34d9e30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_41ab07075fd34c81950e286d55f99773","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d6f3fc6d7044979954d35d1165a95b7","value":9085657}},"ea0d895d360348b79a360a2cdf5f360e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45a450ba946a4206ae885a0f90a31a38","placeholder":"​","style":"IPY_MODEL_d6fe98ac6ee64362b379e0b6a8cb77b0","value":" 9.09M/9.09M [00:00&lt;00:00, 19.2MB/s]"}},"ee96010baa9d4408928ded969b56d8bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8d20fc42b934beda0b011a325485d0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8a3a6727f74beb99d2bc798ddd73b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"41ab07075fd34c81950e286d55f99773":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d6f3fc6d7044979954d35d1165a95b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45a450ba946a4206ae885a0f90a31a38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6fe98ac6ee64362b379e0b6a8cb77b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1899c6e4e8844ffa9872f2239951445d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68fbcfa22db244148bd46d57555ff419","IPY_MODEL_f22ed3310ae54b87aa63cb155a121e09","IPY_MODEL_10b2aed2eae64d0ea39c91f248df29cd"],"layout":"IPY_MODEL_62ac48e73c0b43d18ef99b8e5cff949e"}},"68fbcfa22db244148bd46d57555ff419":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15d55bdf892b4d6781a839673519b035","placeholder":"​","style":"IPY_MODEL_3af4fbaa9ab340a084c91024eb716e16","value":"special_tokens_map.json: 100%"}},"f22ed3310ae54b87aa63cb155a121e09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2851bddab1b54d32a601d83a4749a24a","max":340,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34e88c925179421382fd717998f21df8","value":340}},"10b2aed2eae64d0ea39c91f248df29cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64b6be3b75ab4926b4c88cc239b57e17","placeholder":"​","style":"IPY_MODEL_9e7cbdd6d3d64d13bf52a52044bc0e29","value":" 340/340 [00:00&lt;00:00, 15.6kB/s]"}},"62ac48e73c0b43d18ef99b8e5cff949e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15d55bdf892b4d6781a839673519b035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3af4fbaa9ab340a084c91024eb716e16":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2851bddab1b54d32a601d83a4749a24a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34e88c925179421382fd717998f21df8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64b6be3b75ab4926b4c88cc239b57e17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e7cbdd6d3d64d13bf52a52044bc0e29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ecfd4b74bf84d78a8fa9cbd361c1d8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_99d810f9e1b94a86ab208c73e6e54433","IPY_MODEL_834067237bc843ff87dba8aff6725b26","IPY_MODEL_d77fcc417a0a4ca7bae23bb68ce0ff8a"],"layout":"IPY_MODEL_1bd1ee6fd93347d989ed88096ee8841c"}},"99d810f9e1b94a86ab208c73e6e54433":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5516bc220b754979ba8f1fa1aeb91f7f","placeholder":"​","style":"IPY_MODEL_248feeebe6134eceb49abb90e508aa26","value":"Generating train split: "}},"834067237bc843ff87dba8aff6725b26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e348de068104a20b3bdcef3425a579b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d0ffdd00063a4f759da25a528633126e","value":1}},"d77fcc417a0a4ca7bae23bb68ce0ff8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98ae9874aa934166b72617cdaa3181f2","placeholder":"​","style":"IPY_MODEL_7d40221ae7d84798a4ee1a2ba43fcf01","value":" 248/0 [00:00&lt;00:00, 832.28 examples/s]"}},"1bd1ee6fd93347d989ed88096ee8841c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5516bc220b754979ba8f1fa1aeb91f7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"248feeebe6134eceb49abb90e508aa26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e348de068104a20b3bdcef3425a579b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"d0ffdd00063a4f759da25a528633126e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98ae9874aa934166b72617cdaa3181f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d40221ae7d84798a4ee1a2ba43fcf01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"063b7e1868054551867769ea11f8cf57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e7f961a82c04e269c9690a3cd8550cb","IPY_MODEL_6f9acddcab234887a195611032c6000c","IPY_MODEL_d14619edcf4d4c89b1067323bf8571d1"],"layout":"IPY_MODEL_14f05276e051472fb2946346e2fb288d"}},"8e7f961a82c04e269c9690a3cd8550cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abd85ca20d474b5b98854f6c17e0468b","placeholder":"​","style":"IPY_MODEL_4ef9cf759ab14f428e768a66a96b3782","value":"Map: 100%"}},"6f9acddcab234887a195611032c6000c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5da6bd4049954538b42b6c5b72177428","max":248,"min":0,"orientation":"horizontal","style":"IPY_MODEL_708fa3faaef54b9ca55bcb60186c739f","value":248}},"d14619edcf4d4c89b1067323bf8571d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67f43945626c4f2d92ad02df4ef90f1a","placeholder":"​","style":"IPY_MODEL_80b4ece897024d608cd3abe3bba7e8ca","value":" 248/248 [00:00&lt;00:00, 2782.13 examples/s]"}},"14f05276e051472fb2946346e2fb288d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abd85ca20d474b5b98854f6c17e0468b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ef9cf759ab14f428e768a66a96b3782":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5da6bd4049954538b42b6c5b72177428":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708fa3faaef54b9ca55bcb60186c739f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67f43945626c4f2d92ad02df4ef90f1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80b4ece897024d608cd3abe3bba7e8ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f40a7dcff6e4f3cb2ca4934a4daacdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba2b964b82284a07baa699e3bf250d4f","IPY_MODEL_1e842c73c72d456bb99d3f3ee3a9b11f","IPY_MODEL_2966aaaa63cc481e85d5d34c0d72bae5"],"layout":"IPY_MODEL_989bcaf1851f425ca8c07e0952964163"}},"ba2b964b82284a07baa699e3bf250d4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfccea4537664ede9d9efffc1874f058","placeholder":"​","style":"IPY_MODEL_1b0fb46ed5a4459296b8ca09d931b461","value":"Map (num_proc=2): 100%"}},"1e842c73c72d456bb99d3f3ee3a9b11f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8686e9dce9fd4d05bbcb3a40653ae811","max":248,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8b283713df54d6b865f166d8a60120a","value":248}},"2966aaaa63cc481e85d5d34c0d72bae5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c9064e55ded4ad5b63e41790683f7cf","placeholder":"​","style":"IPY_MODEL_446445e44bd34e68a41b69847cce5024","value":" 248/248 [00:04&lt;00:00, 60.16 examples/s]"}},"989bcaf1851f425ca8c07e0952964163":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfccea4537664ede9d9efffc1874f058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b0fb46ed5a4459296b8ca09d931b461":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8686e9dce9fd4d05bbcb3a40653ae811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8b283713df54d6b865f166d8a60120a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c9064e55ded4ad5b63e41790683f7cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"446445e44bd34e68a41b69847cce5024":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}